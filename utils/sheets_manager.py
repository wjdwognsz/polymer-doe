# ğŸ“Š utils/sheets_manager.py - Google Sheets ê´€ë¦¬ì
"""
Google Sheetsë¥¼ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ì‚¬ìš©í•˜ëŠ” í†µí•© ê´€ë¦¬ ì‹œìŠ¤í…œ
- CRUD ì‘ì—…, ìºì‹±, ë°°ì¹˜ ì²˜ë¦¬, íŠ¸ëœì­ì…˜ ê´€ë¦¬
- ë¹„ë™ê¸° ì²˜ë¦¬ ë° ì‹¤ì‹œê°„ ë™ê¸°í™” ì§€ì›
"""

# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from queue import Queue, Empty
import hashlib
import uuid
import os
from functools import lru_cache, wraps

# Google API
try:
    from google.oauth2 import service_account
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
    from google.auth.transport.requests import Request
except ImportError:
    print("Google API ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client")

# ë°ì´í„° ì²˜ë¦¬
import pandas as pd
import numpy as np
import streamlit as st

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# Google Sheets API ì„¤ì •
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
API_VERSION = 'v4'
RATE_LIMIT_PER_MINUTE = 60  # Google Sheets API ì œí•œ
BATCH_UPDATE_LIMIT = 1000   # ë°°ì¹˜ë‹¹ ìµœëŒ€ ì—…ë°ì´íŠ¸ ìˆ˜

# ì‹œíŠ¸ ì´ë¦„ ìƒìˆ˜
SHEET_NAMES = {
    'users': 'Users',
    'projects': 'Projects',
    'experiments': 'Experiments',
    'results': 'Results',
    'comments': 'Comments',
    'files': 'Files',
    'notifications': 'Notifications',
    'activity_log': 'Activity_Log',
    'system_config': 'System_Config',
    'templates': 'Templates',
    'modules': 'Modules'
}

# ìºì‹œ ì„¤ì •
CACHE_TTL = {
    'users': 300,           # 5ë¶„
    'projects': 60,         # 1ë¶„
    'experiments': 30,      # 30ì´ˆ
    'results': 30,          # 30ì´ˆ
    'static_data': 3600,    # 1ì‹œê°„
    'system_config': 7200   # 2ì‹œê°„
}

# ì¬ì‹œë„ ì„¤ì •
RETRY_DELAYS = [0.5, 1.0, 2.0, 4.0, 8.0]  # ì§€ìˆ˜ ë°±ì˜¤í”„
MAX_RETRIES = len(RETRY_DELAYS)

# ë°ì´í„° íƒ€ì… ë§¤í•‘
COLUMN_TYPES = {
    'user_id': str,
    'project_id': str,
    'experiment_id': str,
    'created_at': 'datetime',
    'updated_at': 'datetime',
    'last_login': 'datetime',
    'is_active': bool,
    'points': int,
    'level': str,
    'settings': 'json',
    'factors': 'json',
    'responses': 'json',
    'collaborators': 'json',
    'metadata': 'json',
    'results_data': 'json'
}


class GoogleSheetsManager:
    """Google Sheets ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ì"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.service = None
        self.spreadsheet_id = None
        self.cache = {}
        self.cache_timestamps = {}
        self.rate_limiter = RateLimiter(RATE_LIMIT_PER_MINUTE)
        self.batch_queue = Queue()
        self.batch_processor_running = False
        self.batch_processor_thread = None
        self._lock = threading.Lock()
        self._initialize_service()
        
    def _initialize_service(self):
        """Google Sheets ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            # Streamlit secretsì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            if 'google_sheets_url' in st.secrets:
                self.spreadsheet_id = st.secrets['google_sheets_url']
            else:
                logger.error("Google Sheets URLì´ secretsì— ì—†ìŠµë‹ˆë‹¤")
                return
                
            # ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            if 'google_service_account' in st.secrets:
                service_account_info = st.secrets['google_service_account']
                credentials = service_account.Credentials.from_service_account_info(
                    service_account_info, scopes=SCOPES
                )
                
                # ì„œë¹„ìŠ¤ ë¹Œë“œ
                self.service = build('sheets', 'v4', credentials=credentials)
                logger.info("Google Sheets ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ")
                
                # ë°°ì¹˜ í”„ë¡œì„¸ì„œ ì‹œì‘
                self._start_batch_processor()
                
            else:
                logger.error("Google ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ê°€ secretsì— ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.error(f"Google Sheets ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            
    def _start_batch_processor(self):
        """ë°°ì¹˜ í”„ë¡œì„¸ì„œ ì‹œì‘"""
        if not self.batch_processor_running:
            self.batch_processor_running = True
            self.batch_processor_thread = threading.Thread(
                target=self._batch_processor,
                daemon=True
            )
            self.batch_processor_thread.start()
            
    def _stop_batch_processor(self):
        """ë°°ì¹˜ í”„ë¡œì„¸ì„œ ì¤‘ì§€"""
        self.batch_processor_running = False
        if self.batch_processor_thread:
            self.batch_processor_thread.join()
            
    def _retry_with_backoff(self, func, *args, **kwargs):
        """ì¬ì‹œë„ ë¡œì§"""
        for i, delay in enumerate(RETRY_DELAYS):
            try:
                return func(*args, **kwargs)
            except HttpError as e:
                if e.resp.status in [429, 500, 503]:  # Rate limit or server error
                    if i < len(RETRY_DELAYS) - 1:
                        time.sleep(delay)
                        continue
                raise
            except Exception as e:
                if i < len(RETRY_DELAYS) - 1:
                    time.sleep(delay)
                    continue
                raise
                
    def _get_cache_key(self, sheet_name: str, **kwargs) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{sheet_name}:{json.dumps(kwargs, sort_keys=True)}"
        return hashlib.md5(key_data.encode()).hexdigest()
        
    def _is_cache_valid(self, cache_key: str, sheet_name: str) -> bool:
        """ìºì‹œ ìœ íš¨ì„± í™•ì¸"""
        if cache_key not in self.cache:
            return False
            
        timestamp = self.cache_timestamps.get(cache_key, 0)
        ttl = CACHE_TTL.get(sheet_name, 60)
        return time.time() - timestamp < ttl
        
    def _convert_types(self, df: pd.DataFrame, sheet_name: str) -> pd.DataFrame:
        """ë°ì´í„° íƒ€ì… ë³€í™˜"""
        for column in df.columns:
            if column in COLUMN_TYPES:
                col_type = COLUMN_TYPES[column]
                
                try:
                    if col_type == 'datetime':
                        df[column] = pd.to_datetime(df[column], errors='coerce')
                    elif col_type == 'json':
                        df[column] = df[column].apply(self._parse_json)
                    elif col_type == bool:
                        df[column] = df[column].astype(str).str.lower() == 'true'
                    elif col_type == int:
                        df[column] = pd.to_numeric(df[column], errors='coerce').fillna(0).astype(int)
                    elif col_type == str:
                        df[column] = df[column].astype(str)
                except Exception as e:
                    logger.warning(f"íƒ€ì… ë³€í™˜ ì‹¤íŒ¨ {column}: {str(e)}")
                    
        return df
        
    def _parse_json(self, value):
        """JSON íŒŒì‹±"""
        if pd.isna(value) or value == '':
            return {}
        if isinstance(value, (dict, list)):
            return value
        try:
            return json.loads(value)
        except:
            return {}
            
    def _apply_filters(self, df: pd.DataFrame, filters: Dict[str, Any]) -> pd.DataFrame:
        """í•„í„° ì ìš©"""
        for column, value in filters.items():
            if column in df.columns:
                if isinstance(value, list):
                    df = df[df[column].isin(value)]
                elif isinstance(value, dict):
                    # ë²”ìœ„ í•„í„° (ì˜ˆ: {'$gte': 10, '$lte': 100})
                    if '$gte' in value:
                        df = df[df[column] >= value['$gte']]
                    if '$gt' in value:
                        df = df[df[column] > value['$gt']]
                    if '$lte' in value:
                        df = df[df[column] <= value['$lte']]
                    if '$lt' in value:
                        df = df[df[column] < value['$lt']]
                    if '$ne' in value:
                        df = df[df[column] != value['$ne']]
                else:
                    df = df[df[column] == value]
                    
        return df
        
    # ===== ì½ê¸° ì‘ì—… =====
    
    def read_sheet(self,
                   sheet_name: str,
                   filters: Optional[Dict[str, Any]] = None,
                   columns: Optional[List[str]] = None,
                   order_by: Optional[str] = None,
                   limit: Optional[int] = None,
                   offset: int = 0,
                   cache: bool = True) -> pd.DataFrame:
        """
        ì‹œíŠ¸ ë°ì´í„° ì½ê¸°
        
        Args:
            sheet_name: ì‹œíŠ¸ ì´ë¦„
            filters: í•„í„° ì¡°ê±´
            columns: ì„ íƒí•  ì»¬ëŸ¼
            order_by: ì •ë ¬ ê¸°ì¤€ (- prefix for desc)
            limit: ìµœëŒ€ í–‰ ìˆ˜
            offset: ì‹œì‘ ìœ„ì¹˜
            cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            pd.DataFrame: ì¡°íšŒëœ ë°ì´í„°
        """
        if not self.service:
            logger.error("Google Sheets ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
            
        # ìºì‹œ í™•ì¸
        cache_key = self._get_cache_key(sheet_name, filters=filters, columns=columns)
        if cache and self._is_cache_valid(cache_key, sheet_name):
            df = self.cache[cache_key].copy()
        else:
            # Rate limiting
            self.rate_limiter.wait_if_needed()
            
            try:
                # ì „ì²´ ë°ì´í„° ì½ê¸°
                range_name = f"{SHEET_NAMES.get(sheet_name, sheet_name)}!A:Z"
                result = self._retry_with_backoff(
                    self.service.spreadsheets().values().get,
                    spreadsheetId=self.spreadsheet_id,
                    range=range_name
                )
                
                values = result.get('values', [])
                if not values:
                    return pd.DataFrame()
                    
                # DataFrame ìƒì„±
                df = pd.DataFrame(values[1:], columns=values[0])
                
                # ë°ì´í„° íƒ€ì… ë³€í™˜
                df = self._convert_types(df, sheet_name)
                
                # ìºì‹œ ì €ì¥
                if cache:
                    self.cache[cache_key] = df.copy()
                    self.cache_timestamps[cache_key] = time.time()
                    
            except Exception as e:
                logger.error(f"ì‹œíŠ¸ ì½ê¸° ì˜¤ë¥˜ ({sheet_name}): {str(e)}")
                return pd.DataFrame()
                
        # í•„í„° ì ìš©
        if filters:
            df = self._apply_filters(df, filters)
            
        # ì»¬ëŸ¼ ì„ íƒ
        if columns:
            available_columns = [col for col in columns if col in df.columns]
            df = df[available_columns]
            
        # ì •ë ¬
        if order_by:
            ascending = True
            if order_by.startswith('-'):
                order_by = order_by[1:]
                ascending = False
            if order_by in df.columns:
                df = df.sort_values(order_by, ascending=ascending)
                
        # í˜ì´ì§€ë„¤ì´ì…˜
        if limit:
            df = df.iloc[offset:offset + limit]
        elif offset:
            df = df.iloc[offset:]
            
        return df
        
    def read_row(self, sheet_name: str, row_id: str, id_column: str = None) -> Optional[Dict]:
        """
        ë‹¨ì¼ í–‰ ì½ê¸°
        
        Args:
            sheet_name: ì‹œíŠ¸ ì´ë¦„
            row_id: í–‰ ID
            id_column: ID ì»¬ëŸ¼ëª… (ê¸°ë³¸: {sheet_name}_id)
            
        Returns:
            Dict: í–‰ ë°ì´í„° ë˜ëŠ” None
        """
        if not id_column:
            # ê¸°ë³¸ ID ì»¬ëŸ¼ëª… ì¶”ë¡ 
            if sheet_name == 'users':
                id_column = 'user_id'
            elif sheet_name == 'projects':
                id_column = 'project_id'
            elif sheet_name == 'experiments':
                id_column = 'experiment_id'
            else:
                id_column = f"{sheet_name}_id"
                
        df = self.read_sheet(sheet_name, filters={id_column: row_id}, limit=1)
        if not df.empty:
            return df.iloc[0].to_dict()
        return None
        
    # ===== ì“°ê¸° ì‘ì—… =====
    
    def write_row(self, sheet_name: str, data: Dict[str, Any], return_id: bool = True) -> Optional[str]:
        """
        ìƒˆ í–‰ ì¶”ê°€
        
        Args:
            sheet_name: ì‹œíŠ¸ ì´ë¦„
            data: ì¶”ê°€í•  ë°ì´í„°
            return_id: ID ë°˜í™˜ ì—¬ë¶€
            
        Returns:
            str: ìƒì„±ëœ í–‰ ID (ì„ íƒì )
        """
        if not self.service:
            logger.error("Google Sheets ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None
            
        try:
            # ID ìƒì„±
            if return_id:
                id_column = self._get_id_column(sheet_name)
                if id_column not in data:
                    data[id_column] = self._generate_id()
                    
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
            data['created_at'] = datetime.now().isoformat()
            data['updated_at'] = datetime.now().isoformat()
            
            # í˜„ì¬ ì‹œíŠ¸ ë°ì´í„° ì½ê¸° (í—¤ë” í™•ì¸ìš©)
            range_name = f"{SHEET_NAMES.get(sheet_name, sheet_name)}!A1:Z1"
            result = self._retry_with_backoff(
                self.service.spreadsheets().values().get,
                spreadsheetId=self.spreadsheet_id,
                range=range_name
            )
            
            headers = result.get('values', [[]])[0] if result.get('values') else []
            
            # ìƒˆ ì»¬ëŸ¼ ì¶”ê°€ (í•„ìš”ì‹œ)
            new_columns = [col for col in data.keys() if col not in headers]
            if new_columns:
                headers.extend(new_columns)
                self._update_headers(sheet_name, headers)
                
            # ë°ì´í„° í–‰ ìƒì„±
            row_values = []
            for header in headers:
                value = data.get(header, '')
                # JSON í•„ë“œ ì²˜ë¦¬
                if header in COLUMN_TYPES and COLUMN_TYPES[header] == 'json':
                    if isinstance(value, (dict, list)):
                        value = json.dumps(value)
                row_values.append(str(value))
                
            # í–‰ ì¶”ê°€
            range_name = f"{SHEET_NAMES.get(sheet_name, sheet_name)}!A:Z"
            body = {'values': [row_values]}
            
            self.rate_limiter.wait_if_needed()
            self._retry_with_backoff(
                self.service.spreadsheets().values().append,
                spreadsheetId=self.spreadsheet_id,
                range=range_name,
                valueInputOption='RAW',
                body=body
            )
            
            # ìºì‹œ ë¬´íš¨í™”
            self._invalidate_cache(sheet_name)
            
            return data.get(id_column) if return_id and id_column else None
            
        except Exception as e:
            logger.error(f"í–‰ ì¶”ê°€ ì˜¤ë¥˜ ({sheet_name}): {str(e)}")
            return None
            
    def update_row(self, sheet_name: str, row_id: str, updates: Dict[str, Any], id_column: str = None) -> bool:
        """
        í–‰ ì—…ë°ì´íŠ¸
        
        Args:
            sheet_name: ì‹œíŠ¸ ì´ë¦„
            row_id: í–‰ ID
            updates: ì—…ë°ì´íŠ¸í•  ë°ì´í„°
            id_column: ID ì»¬ëŸ¼ëª…
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        if not self.service:
            return False
            
        try:
            if not id_column:
                id_column = self._get_id_column(sheet_name)
                
            # í˜„ì¬ ë°ì´í„° ì½ê¸°
            df = self.read_sheet(sheet_name, cache=False)
            if df.empty:
                return False
                
            # í–‰ ì°¾ê¸°
            row_mask = df[id_column] == row_id
            if not row_mask.any():
                logger.warning(f"í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {row_id}")
                return False
                
            row_index = df[row_mask].index[0] + 2  # í—¤ë” + 1-based index
            
            # ì—…ë°ì´íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„
            updates['updated_at'] = datetime.now().isoformat()
            
            # ì—…ë°ì´íŠ¸ ë°ì´í„° ì¤€ë¹„
            update_requests = []
            for column, value in updates.items():
                if column in df.columns:
                    col_index = df.columns.get_loc(column)
                    
                    # JSON í•„ë“œ ì²˜ë¦¬
                    if column in COLUMN_TYPES and COLUMN_TYPES[column] == 'json':
                        if isinstance(value, (dict, list)):
                            value = json.dumps(value)
                            
                    update_requests.append({
                        'range': f"{SHEET_NAMES.get(sheet_name, sheet_name)}!{chr(65 + col_index)}{row_index}",
                        'values': [[str(value)]]
                    })
                    
            if update_requests:
                # ë°°ì¹˜ ì—…ë°ì´íŠ¸
                body = {
                    'valueInputOption': 'RAW',
                    'data': update_requests
                }
                
                self.rate_limiter.wait_if_needed()
                self._retry_with_backoff(
                    self.service.spreadsheets().values().batchUpdate,
                    spreadsheetId=self.spreadsheet_id,
                    body=body
                )
                
                # ìºì‹œ ë¬´íš¨í™”
                self._invalidate_cache(sheet_name)
                
                return True
                
        except Exception as e:
            logger.error(f"í–‰ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜ ({sheet_name}): {str(e)}")
            
        return False
        
    def delete_row(self, sheet_name: str, row_id: str, id_column: str = None) -> bool:
        """
        í–‰ ì‚­ì œ (ì†Œí”„íŠ¸ ì‚­ì œ)
        
        Args:
            sheet_name: ì‹œíŠ¸ ì´ë¦„
            row_id: í–‰ ID
            id_column: ID ì»¬ëŸ¼ëª…
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        # ì†Œí”„íŠ¸ ì‚­ì œ êµ¬í˜„ (is_deleted í”Œë˜ê·¸ ì„¤ì •)
        return self.update_row(sheet_name, row_id, {'is_deleted': True}, id_column)
        
    # ===== ë°°ì¹˜ ì‘ì—… =====
    
    def batch_write(self, sheet_name: str, data_list: List[Dict[str, Any]]) -> int:
        """
        ì—¬ëŸ¬ í–‰ ì¼ê´„ ì¶”ê°€
        
        Args:
            sheet_name: ì‹œíŠ¸ ì´ë¦„
            data_list: ì¶”ê°€í•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            int: ì¶”ê°€ëœ í–‰ ìˆ˜
        """
        if not self.service or not data_list:
            return 0
            
        try:
            # í—¤ë” í™•ì¸
            range_name = f"{SHEET_NAMES.get(sheet_name, sheet_name)}!A1:Z1"
            result = self._retry_with_backoff(
                self.service.spreadsheets().values().get,
                spreadsheetId=self.spreadsheet_id,
                range=range_name
            )
            
            headers = result.get('values', [[]])[0] if result.get('values') else []
            
            # ëª¨ë“  ì»¬ëŸ¼ ìˆ˜ì§‘
            all_columns = set(headers)
            for data in data_list:
                all_columns.update(data.keys())
                
            # ìƒˆ ì»¬ëŸ¼ ì¶”ê°€
            new_columns = [col for col in all_columns if col not in headers]
            if new_columns:
                headers = list(headers) + new_columns
                self._update_headers(sheet_name, headers)
                
            # ë°ì´í„° í–‰ ì¤€ë¹„
            rows = []
            id_column = self._get_id_column(sheet_name)
            
            for data in data_list:
                # ID ë° íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                if id_column not in data:
                    data[id_column] = self._generate_id()
                data['created_at'] = datetime.now().isoformat()
                data['updated_at'] = datetime.now().isoformat()
                
                # í–‰ ë°ì´í„° ìƒì„±
                row = []
                for header in headers:
                    value = data.get(header, '')
                    if header in COLUMN_TYPES and COLUMN_TYPES[header] == 'json':
                        if isinstance(value, (dict, list)):
                            value = json.dumps(value)
                    row.append(str(value))
                rows.append(row)
                
            # ë°°ì¹˜ ì¶”ê°€
            if rows:
                range_name = f"{SHEET_NAMES.get(sheet_name, sheet_name)}!A:Z"
                body = {'values': rows}
                
                self.rate_limiter.wait_if_needed()
                self._retry_with_backoff(
                    self.service.spreadsheets().values().append,
                    spreadsheetId=self.spreadsheet_id,
                    range=range_name,
                    valueInputOption='RAW',
                    body=body
                )
                
                # ìºì‹œ ë¬´íš¨í™”
                self._invalidate_cache(sheet_name)
                
                return len(rows)
                
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì¶”ê°€ ì˜¤ë¥˜ ({sheet_name}): {str(e)}")
            
        return 0
        
    def batch_update(self, sheet_name: str, updates: List[Dict[str, Any]], id_column: str = None) -> int:
        """
        ì—¬ëŸ¬ í–‰ ì¼ê´„ ì—…ë°ì´íŠ¸
        
        Args:
            sheet_name: ì‹œíŠ¸ ì´ë¦„
            updates: ì—…ë°ì´íŠ¸ ë¦¬ìŠ¤íŠ¸ (ê° í•­ëª©ì€ idì™€ updates í¬í•¨)
            id_column: ID ì»¬ëŸ¼ëª…
            
        Returns:
            int: ì—…ë°ì´íŠ¸ëœ í–‰ ìˆ˜
        """
        if not self.service or not updates:
            return 0
            
        success_count = 0
        
        # ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
        batch_size = 100
        for i in range(0, len(updates), batch_size):
            batch = updates[i:i + batch_size]
            
            try:
                # í˜„ì¬ ë°ì´í„° ì½ê¸°
                df = self.read_sheet(sheet_name, cache=False)
                if df.empty:
                    continue
                    
                if not id_column:
                    id_column = self._get_id_column(sheet_name)
                    
                # ì—…ë°ì´íŠ¸ ìš”ì²­ ì¤€ë¹„
                update_requests = []
                
                for update_item in batch:
                    row_id = update_item.get('id')
                    update_data = update_item.get('updates', {})
                    
                    if not row_id or not update_data:
                        continue
                        
                    # í–‰ ì°¾ê¸°
                    row_mask = df[id_column] == row_id
                    if not row_mask.any():
                        continue
                        
                    row_index = df[row_mask].index[0] + 2
                    update_data['updated_at'] = datetime.now().isoformat()
                    
                    # ê° ì»¬ëŸ¼ ì—…ë°ì´íŠ¸
                    for column, value in update_data.items():
                        if column in df.columns:
                            col_index = df.columns.get_loc(column)
                            
                            if column in COLUMN_TYPES and COLUMN_TYPES[column] == 'json':
                                if isinstance(value, (dict, list)):
                                    value = json.dumps(value)
                                    
                            update_requests.append({
                                'range': f"{SHEET_NAMES.get(sheet_name, sheet_name)}!{chr(65 + col_index)}{row_index}",
                                'values': [[str(value)]]
                            })
                            
                if update_requests:
                    # ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤í–‰
                    body = {
                        'valueInputOption': 'RAW',
                        'data': update_requests
                    }
                    
                    self.rate_limiter.wait_if_needed()
                    self._retry_with_backoff(
                        self.service.spreadsheets().values().batchUpdate,
                        spreadsheetId=self.spreadsheet_id,
                        body=body
                    )
                    
                    success_count += len(batch)
                    
            except Exception as e:
                logger.error(f"ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
                
        # ìºì‹œ ë¬´íš¨í™”
        if success_count > 0:
            self._invalidate_cache(sheet_name)
            
        return success_count
        
    # ===== íŠ¸ëœì­ì…˜ =====
    
    class Transaction:
        """íŠ¸ëœì­ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        
        def __init__(self, manager):
            self.manager = manager
            self.operations = []
            self.original_data = {}
            
        def add_operation(self, op_type: str, sheet_name: str, data: Any):
            """ì‘ì—… ì¶”ê°€"""
            self.operations.append({
                'type': op_type,
                'sheet': sheet_name,
                'data': data,
                'timestamp': datetime.now()
            })
            
        def __enter__(self):
            return self
            
        def __exit__(self, exc_type, exc_val, exc_tb):
            if exc_type is None:
                # ì»¤ë°‹
                self._commit()
            else:
                # ë¡¤ë°±
                self._rollback()
                
        def _commit(self):
            """íŠ¸ëœì­ì…˜ ì»¤ë°‹"""
            for op in self.operations:
                try:
                    if op['type'] == 'write':
                        self.manager.write_row(op['sheet'], op['data'])
                    elif op['type'] == 'update':
                        self.manager.update_row(
                            op['sheet'], 
                            op['data']['id'], 
                            op['data']['updates']
                        )
                    elif op['type'] == 'delete':
                        self.manager.delete_row(op['sheet'], op['data'])
                except Exception as e:
                    logger.error(f"íŠ¸ëœì­ì…˜ ì»¤ë°‹ ì˜¤ë¥˜: {str(e)}")
                    self._rollback()
                    raise
                    
        def _rollback(self):
            """íŠ¸ëœì­ì…˜ ë¡¤ë°±"""
            # ê°„ë‹¨í•œ ë¡¤ë°± êµ¬í˜„ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•  ìˆ˜ ìˆìŒ)
            logger.warning("íŠ¸ëœì­ì…˜ ë¡¤ë°± ìˆ˜í–‰")
            
    def transaction(self):
        """íŠ¸ëœì­ì…˜ ì‹œì‘"""
        return self.Transaction(self)
        
    # ===== ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ =====
    
    def _get_id_column(self, sheet_name: str) -> str:
        """ì‹œíŠ¸ë³„ ID ì»¬ëŸ¼ëª… ë°˜í™˜"""
        id_columns = {
            'users': 'user_id',
            'projects': 'project_id',
            'experiments': 'experiment_id',
            'results': 'result_id',
            'comments': 'comment_id',
            'files': 'file_id',
            'notifications': 'notification_id'
        }
        return id_columns.get(sheet_name, f"{sheet_name}_id")
        
    def _generate_id(self) -> str:
        """ê³ ìœ  ID ìƒì„±"""
        return str(uuid.uuid4())
        
    def _update_headers(self, sheet_name: str, headers: List[str]):
        """í—¤ë” ì—…ë°ì´íŠ¸"""
        try:
            range_name = f"{SHEET_NAMES.get(sheet_name, sheet_name)}!A1:Z1"
            body = {'values': [headers]}
            
            self._retry_with_backoff(
                self.service.spreadsheets().values().update,
                spreadsheetId=self.spreadsheet_id,
                range=range_name,
                valueInputOption='RAW',
                body=body
            )
        except Exception as e:
            logger.error(f"í—¤ë” ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")
            
    def _invalidate_cache(self, sheet_name: str = None):
        """ìºì‹œ ë¬´íš¨í™”"""
        with self._lock:
            if sheet_name:
                # íŠ¹ì • ì‹œíŠ¸ì˜ ìºì‹œë§Œ ë¬´íš¨í™”
                keys_to_remove = [
                    key for key in self.cache.keys() 
                    if key.startswith(f"{sheet_name}:")
                ]
                for key in keys_to_remove:
                    self.cache.pop(key, None)
                    self.cache_timestamps.pop(key, None)
            else:
                # ì „ì²´ ìºì‹œ ë¬´íš¨í™”
                self.cache.clear()
                self.cache_timestamps.clear()
                
    def _batch_processor(self):
        """ë°±ê·¸ë¼ìš´ë“œ ë°°ì¹˜ í”„ë¡œì„¸ì„œ"""
        batch = []
        last_flush = time.time()
        
        while self.batch_processor_running:
            try:
                # íì—ì„œ ì‘ì—… ê°€ì ¸ì˜¤ê¸°
                operation = self.batch_queue.get(timeout=1.0)
                batch.append(operation)
                
                # ë°°ì¹˜ í¬ê¸°ë‚˜ ì‹œê°„ ì¡°ê±´ í™•ì¸
                if (len(batch) >= 100 or time.time() - last_flush > 5.0):
                    self._flush_batch(batch)
                    batch = []
                    last_flush = time.time()
                    
            except Empty:
                # íƒ€ì„ì•„ì›ƒ ì‹œ ëŒ€ê¸° ì¤‘ì¸ ë°°ì¹˜ ì²˜ë¦¬
                if batch:
                    self._flush_batch(batch)
                    batch = []
                    last_flush = time.time()
                    
    def _flush_batch(self, batch: List[Dict]):
        """ë°°ì¹˜ ì‹¤í–‰"""
        if not batch:
            return
            
        # ì‹œíŠ¸ë³„ë¡œ ê·¸ë£¹í™”
        sheet_operations = defaultdict(list)
        for op in batch:
            sheet_operations[op['sheet']].append(op)
            
        # ê° ì‹œíŠ¸ë³„ë¡œ ì²˜ë¦¬
        for sheet_name, ops in sheet_operations.items():
            write_ops = [op for op in ops if op['type'] == 'write']
            update_ops = [op for op in ops if op['type'] == 'update']
            
            if write_ops:
                data_list = [op['data'] for op in write_ops]
                self.batch_write(sheet_name, data_list)
                
            if update_ops:
                updates = [
                    {'id': op['data']['id'], 'updates': op['data']['updates']} 
                    for op in update_ops
                ]
                self.batch_update(sheet_name, updates)
                
    # ===== íŠ¹ìˆ˜ ë©”ì„œë“œ =====
    
    def get_sheet_stats(self, sheet_name: str) -> Dict[str, Any]:
        """ì‹œíŠ¸ í†µê³„ ì •ë³´"""
        try:
            df = self.read_sheet(sheet_name)
            return {
                'total_rows': len(df),
                'columns': list(df.columns),
                'memory_usage': df.memory_usage(deep=True).sum(),
                'last_updated': df['updated_at'].max() if 'updated_at' in df.columns else None
            }
        except Exception as e:
            logger.error(f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {}
            
    def export_to_csv(self, sheet_name: str, file_path: str) -> bool:
        """CSVë¡œ ë‚´ë³´ë‚´ê¸°"""
        try:
            df = self.read_sheet(sheet_name)
            df.to_csv(file_path, index=False)
            return True
        except Exception as e:
            logger.error(f"CSV ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {str(e)}")
            return False
            
    def import_from_csv(self, sheet_name: str, file_path: str) -> int:
        """CSVì—ì„œ ê°€ì ¸ì˜¤ê¸°"""
        try:
            df = pd.read_csv(file_path)
            data_list = df.to_dict('records')
            return self.batch_write(sheet_name, data_list)
        except Exception as e:
            logger.error(f"CSV ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {str(e)}")
            return 0
            

class RateLimiter:
    """API í˜¸ì¶œ ì†ë„ ì œí•œ"""
    
    def __init__(self, calls_per_minute: int):
        self.calls_per_minute = calls_per_minute
        self.calls = []
        self._lock = threading.Lock()
        
    def wait_if_needed(self):
        """í•„ìš”ì‹œ ëŒ€ê¸°"""
        with self._lock:
            now = time.time()
            # 1ë¶„ ì´ìƒ ì§€ë‚œ í˜¸ì¶œ ì œê±°
            self.calls = [call_time for call_time in self.calls if now - call_time < 60]
            
            if len(self.calls) >= self.calls_per_minute:
                # ê°€ì¥ ì˜¤ë˜ëœ í˜¸ì¶œë¡œë¶€í„° 1ë¶„ì´ ì§€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
                sleep_time = 60 - (now - self.calls[0]) + 0.1
                if sleep_time > 0:
                    time.sleep(sleep_time)
                    
            self.calls.append(time.time())


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_sheets_manager_instance = None


def get_sheets_manager() -> GoogleSheetsManager:
    """ì‹±ê¸€í†¤ GoogleSheetsManager ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _sheets_manager_instance
    if _sheets_manager_instance is None:
        _sheets_manager_instance = GoogleSheetsManager()
    return _sheets_manager_instance


# ê°„í¸ í•¨ìˆ˜ë“¤
def read_users(filters: Optional[Dict] = None, **kwargs) -> pd.DataFrame:
    """ì‚¬ìš©ì ë°ì´í„° ì½ê¸°"""
    return get_sheets_manager().read_sheet('users', filters=filters, **kwargs)


def read_projects(filters: Optional[Dict] = None, **kwargs) -> pd.DataFrame:
    """í”„ë¡œì íŠ¸ ë°ì´í„° ì½ê¸°"""
    return get_sheets_manager().read_sheet('projects', filters=filters, **kwargs)


def read_experiments(filters: Optional[Dict] = None, **kwargs) -> pd.DataFrame:
    """ì‹¤í—˜ ë°ì´í„° ì½ê¸°"""
    return get_sheets_manager().read_sheet('experiments', filters=filters, **kwargs)


def write_user(data: Dict[str, Any]) -> Optional[str]:
    """ì‚¬ìš©ì ì¶”ê°€"""
    return get_sheets_manager().write_row('users', data)


def write_project(data: Dict[str, Any]) -> Optional[str]:
    """í”„ë¡œì íŠ¸ ì¶”ê°€"""
    return get_sheets_manager().write_row('projects', data)


def write_experiment(data: Dict[str, Any]) -> Optional[str]:
    """ì‹¤í—˜ ì¶”ê°€"""
    return get_sheets_manager().write_row('experiments', data)


def update_user(user_id: str, updates: Dict[str, Any]) -> bool:
    """ì‚¬ìš©ì ì •ë³´ ì—…ë°ì´íŠ¸"""
    return get_sheets_manager().update_row('users', user_id, updates)


def update_project(project_id: str, updates: Dict[str, Any]) -> bool:
    """í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸"""
    return get_sheets_manager().update_row('projects', project_id, updates)


def update_experiment(experiment_id: str, updates: Dict[str, Any]) -> bool:
    """ì‹¤í—˜ ì—…ë°ì´íŠ¸"""
    return get_sheets_manager().update_row('experiments', experiment_id, updates)
