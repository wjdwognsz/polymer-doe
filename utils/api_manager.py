# utils/api_manager.py
"""
AI API í†µí•© ê´€ë¦¬ì
6ê°œ AI ì—”ì§„ê³¼ ë‹¤ì–‘í•œ ê³¼í•™ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤.
ì˜¤í”„ë¼ì¸ ìš°ì„  ì„¤ê³„ë¡œ ìºì‹±ê³¼ í´ë°± ë©”ì»¤ë‹ˆì¦˜ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import json
import logging
import asyncio
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union, Callable
from dataclasses import dataclass, field, asdict
from collections import defaultdict, deque
from functools import wraps, lru_cache
from enum import Enum
import hashlib
import threading
from pathlib import Path
import base64
from cryptography.fernet import Fernet

# ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st
import pandas as pd
import numpy as np
from tenacity import retry, stop_after_attempt, wait_exponential
import aiohttp
import httpx

# AI ë¼ì´ë¸ŒëŸ¬ë¦¬ - ì„ íƒì  import
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    logging.warning("Google Gemini API ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

try:
    from openai import AsyncOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    logging.warning("OpenAI API ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

try:
    from groq import AsyncGroq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False
    logging.warning("Groq API ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

try:
    from transformers import pipeline
    import torch
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    HUGGINGFACE_AVAILABLE = False
    logging.warning("HuggingFace ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ê³¼í•™ ë°ì´í„°ë² ì´ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from mp_api.client import MPRester
    MATERIALS_PROJECT_AVAILABLE = True
except ImportError:
    MATERIALS_PROJECT_AVAILABLE = False
    logging.warning("Materials Project API ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

try:
    import pubchempy as pcp
    PUBCHEM_AVAILABLE = True
except ImportError:
    PUBCHEM_AVAILABLE = False
    logging.warning("PubChemPy ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

try:
    from github import Github
    GITHUB_AVAILABLE = True
except ImportError:
    GITHUB_AVAILABLE = False
    logging.warning("PyGithub ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ë‚´ë¶€ ëª¨ë“ˆ
from utils.database_manager import get_database_manager
from utils.common_ui import show_error, show_warning, show_info, show_success

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


# ============================================================================
# Enums ë° ë°ì´í„° í´ë˜ìŠ¤
# ============================================================================

class AIEngineType(Enum):
    """AI ì—”ì§„ íƒ€ì…"""
    GEMINI = "gemini"
    GROK = "grok"
    GROQ = "groq"
    SAMBANOVA = "sambanova"
    DEEPSEEK = "deepseek"
    HUGGINGFACE = "huggingface"


class APICategory(Enum):
    """API ì¹´í…Œê³ ë¦¬"""
    AI_ENGINE = "ai_engine"
    SCIENCE_DB = "science_db"
    DATA_REPO = "data_repo"


class ResponseStatus(Enum):
    """API ì‘ë‹µ ìƒíƒœ"""
    SUCCESS = "success"
    ERROR = "error"
    RATE_LIMITED = "rate_limited"
    TIMEOUT = "timeout"
    CACHED = "cached"


@dataclass
class APIConfig:
    """API ì„¤ì •"""
    engine_type: AIEngineType
    model_name: str
    api_key_id: str
    max_tokens: int = 2048
    temperature: float = 0.7
    timeout: int = 30
    cache_ttl: int = 3600
    features: List[str] = field(default_factory=list)


@dataclass
class APIResponse:
    """API ì‘ë‹µ"""
    status: ResponseStatus
    data: Optional[Any] = None
    error: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    latency: float = 0.0
    cached: bool = False


@dataclass
class APIUsage:
    """API ì‚¬ìš©ëŸ‰ ì¶”ì """
    api_id: str
    user_id: str
    timestamp: datetime
    tokens_used: Optional[int] = None
    cost: Optional[float] = None
    success: bool = True
    error_type: Optional[str] = None
    latency: float = 0.0


# ============================================================================
# ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
# ============================================================================

class EncryptionManager:
    """API í‚¤ ì•”í˜¸í™” ê´€ë¦¬"""
    
    def __init__(self):
        self.key = self._get_or_create_key()
        self.cipher = Fernet(self.key)
    
    def _get_or_create_key(self) -> bytes:
        """ì•”í˜¸í™” í‚¤ ìƒì„± ë˜ëŠ” ë¡œë“œ"""
        key_file = Path.home() / '.polymer_doe' / 'api_key.key'
        key_file.parent.mkdir(exist_ok=True)
        
        if key_file.exists():
            return key_file.read_bytes()
        else:
            key = Fernet.generate_key()
            key_file.write_bytes(key)
            return key
    
    def encrypt(self, value: str) -> str:
        """ë¬¸ìì—´ ì•”í˜¸í™”"""
        return self.cipher.encrypt(value.encode()).decode()
    
    def decrypt(self, encrypted: str) -> str:
        """ë¬¸ìì—´ ë³µí˜¸í™”"""
        return self.cipher.decrypt(encrypted.encode()).decode()


class RateLimiter:
    """API í˜¸ì¶œ ì œí•œ ê´€ë¦¬"""
    
    def __init__(self, calls_per_minute: int = 60, calls_per_day: Optional[int] = None):
        self.calls_per_minute = calls_per_minute
        self.calls_per_day = calls_per_day
        self.minute_calls = deque()
        self.day_calls = deque()
        self.lock = threading.Lock()
    
    def check_and_add(self) -> Tuple[bool, Optional[float]]:
        """í˜¸ì¶œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ê¸°ë¡"""
        with self.lock:
            now = time.time()
            
            # 1ë¶„ ì œí•œ í™•ì¸
            minute_ago = now - 60
            self.minute_calls = deque(t for t in self.minute_calls if t > minute_ago)
            
            if len(self.minute_calls) >= self.calls_per_minute:
                wait_time = 60 - (now - self.minute_calls[0])
                return False, wait_time
            
            # ì¼ì¼ ì œí•œ í™•ì¸
            if self.calls_per_day:
                day_ago = now - 86400
                self.day_calls = deque(t for t in self.day_calls if t > day_ago)
                
                if len(self.day_calls) >= self.calls_per_day:
                    wait_time = 86400 - (now - self.day_calls[0])
                    return False, wait_time
            
            # í˜¸ì¶œ ê¸°ë¡
            self.minute_calls.append(now)
            if self.calls_per_day:
                self.day_calls.append(now)
            
            return True, None
    
    def get_remaining(self) -> Dict[str, int]:
        """ë‚¨ì€ í˜¸ì¶œ íšŸìˆ˜"""
        with self.lock:
            now = time.time()
            minute_ago = now - 60
            
            minute_calls = sum(1 for t in self.minute_calls if t > minute_ago)
            remaining_minute = max(0, self.calls_per_minute - minute_calls)
            
            result = {'per_minute': remaining_minute}
            
            if self.calls_per_day:
                day_ago = now - 86400
                day_calls = sum(1 for t in self.day_calls if t > day_ago)
                result['per_day'] = max(0, self.calls_per_day - day_calls)
            
            return result


class ResponseCache:
    """API ì‘ë‹µ ìºì‹œ"""
    
    def __init__(self, default_ttl: int = 3600):
        self.default_ttl = default_ttl
        self.cache = {}
        self.timestamps = {}
        self.lock = threading.Lock()
        self.db_manager = get_database_manager()
    
    def _generate_key(self, api_type: str, params: Dict) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        param_str = json.dumps(params, sort_keys=True)
        return hashlib.md5(f"{api_type}:{param_str}".encode()).hexdigest()
    
    def get(self, api_type: str, params: Dict) -> Optional[Any]:
        """ìºì‹œì—ì„œ ì‘ë‹µ ì¡°íšŒ"""
        key = self._generate_key(api_type, params)
        
        with self.lock:
            # ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
            if key in self.cache:
                timestamp = self.timestamps.get(key, 0)
                if time.time() - timestamp < self.default_ttl:
                    return self.cache[key]
                else:
                    # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                    del self.cache[key]
                    del self.timestamps[key]
            
            # DB ìºì‹œ í™•ì¸
            cached = self.db_manager.cache_get(f"api:{key}")
            if cached:
                self.cache[key] = cached
                self.timestamps[key] = time.time()
                return cached
        
        return None
    
    def set(self, api_type: str, params: Dict, response: Any, 
            ttl: Optional[int] = None):
        """ì‘ë‹µ ìºì‹œì— ì €ì¥"""
        key = self._generate_key(api_type, params)
        ttl = ttl or self.default_ttl
        
        with self.lock:
            # ë©”ëª¨ë¦¬ ìºì‹œ ì €ì¥
            self.cache[key] = response
            self.timestamps[key] = time.time()
            
            # DB ìºì‹œ ì €ì¥
            self.db_manager.cache_set(f"api:{key}", response, ttl)
    
    def clear(self, api_type: Optional[str] = None):
        """ìºì‹œ ì´ˆê¸°í™”"""
        with self.lock:
            if api_type:
                # íŠ¹ì • API íƒ€ì…ë§Œ ì‚­ì œ
                keys_to_remove = [
                    k for k in self.cache.keys() 
                    if k.startswith(f"{api_type}:")
                ]
                for key in keys_to_remove:
                    del self.cache[key]
                    del self.timestamps[key]
            else:
                # ì „ì²´ ìºì‹œ ì‚­ì œ
                self.cache.clear()
                self.timestamps.clear()


class UsageTracker:
    """API ì‚¬ìš©ëŸ‰ ì¶”ì """
    
    def __init__(self):
        self.usage_data = defaultdict(list)
        self.lock = threading.Lock()
        self.db_manager = get_database_manager()
    
    async def track(self, usage: APIUsage):
        """ì‚¬ìš©ëŸ‰ ê¸°ë¡"""
        with self.lock:
            self.usage_data[usage.api_id].append(usage)
            
            # DBì— ì €ì¥
            try:
                self.db_manager.insert('api_usage', {
                    'api_id': usage.api_id,
                    'user_id': usage.user_id,
                    'timestamp': usage.timestamp.isoformat(),
                    'tokens_used': usage.tokens_used,
                    'cost': usage.cost,
                    'success': usage.success,
                    'error_type': usage.error_type,
                    'latency': usage.latency
                })
            except Exception as e:
                logger.error(f"ì‚¬ìš©ëŸ‰ ì¶”ì  DB ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_usage_summary(self, user_id: Optional[str] = None, 
                         period: str = 'day') -> Dict[str, Any]:
        """ì‚¬ìš©ëŸ‰ ìš”ì•½"""
        now = datetime.now()
        
        if period == 'day':
            start_time = now - timedelta(days=1)
        elif period == 'week':
            start_time = now - timedelta(weeks=1)
        elif period == 'month':
            start_time = now - timedelta(days=30)
        else:
            start_time = datetime.min
        
        # í•„í„°ë§
        summary = defaultdict(lambda: {
            'requests': 0, 'tokens': 0, 'cost': 0.0, 
            'errors': 0, 'success_rate': 0.0
        })
        
        for api_id, usages in self.usage_data.items():
            filtered = [u for u in usages if u.timestamp >= start_time]
            if user_id:
                filtered = [u for u in filtered if u.user_id == user_id]
            
            if filtered:
                total = len(filtered)
                success = sum(1 for u in filtered if u.success)
                
                summary[api_id] = {
                    'requests': total,
                    'tokens': sum(u.tokens_used or 0 for u in filtered),
                    'cost': sum(u.cost or 0 for u in filtered),
                    'errors': total - success,
                    'success_rate': (success / total * 100) if total > 0 else 0
                }
        
        return dict(summary)


# ============================================================================
# AI ì—”ì§„ ê¸°ë³¸ í´ë˜ìŠ¤
# ============================================================================

class BaseAIEngine:
    """ëª¨ë“  AI ì—”ì§„ì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config: APIConfig):
        self.config = config
        self.client = None
        self.rate_limiter = None
        self.cache = ResponseCache(config.cache_ttl)
        self.is_available = False
        self.usage_tracker = UsageTracker()
        self._initialize()
    
    def _initialize(self):
        """ì—”ì§„ ì´ˆê¸°í™”"""
        # API í‚¤ í™•ì¸
        if not self.config.api_key_id:
            self.config.api_key_id = self._get_api_key()
        
        if not self.config.api_key_id:
            logger.warning(f"{self.config.engine_type.value} API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # Rate limiter ì„¤ì •
        limits = self._get_rate_limits()
        self.rate_limiter = RateLimiter(
            calls_per_minute=limits.get('per_minute', 60),
            calls_per_day=limits.get('per_day')
        )
        
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self._init_client()
            self.is_available = True
            logger.info(f"{self.config.engine_type.value} ì—”ì§„ ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            logger.error(f"{self.config.engine_type.value} ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            self.is_available = False
    
    def _get_api_key(self) -> Optional[str]:
        """API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
        # 1. í™˜ê²½ ë³€ìˆ˜
        key = os.environ.get(f"{self.config.engine_type.value.upper()}_API_KEY")
        if key:
            return key
        
        # 2. Streamlit secrets
        if hasattr(st, 'secrets'):
            try:
                key = st.secrets.get(f"{self.config.engine_type.value}_api_key")
                if key:
                    return key
            except:
                pass
        
        # 3. ì„¸ì…˜ ìƒíƒœ
        if hasattr(st, 'session_state') and 'api_keys' in st.session_state:
            key = st.session_state.api_keys.get(self.config.engine_type.value)
            if key:
                return key
        
        return None
    
    def _get_rate_limits(self) -> Dict[str, int]:
        """Rate limit ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
        # ê¸°ë³¸ ì œí•œ
        defaults = {
            'gemini': {'per_minute': 60, 'per_day': 1500},
            'grok': {'per_minute': 60},
            'groq': {'per_minute': 30, 'per_day': 14400},
            'sambanova': {'per_minute': 60},
            'deepseek': {'per_minute': 60},
            'huggingface': {'per_minute': 100}
        }
        return defaults.get(self.config.engine_type.value, {'per_minute': 60})
    
    def _init_client(self):
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        raise NotImplementedError
    
    async def generate(self, prompt: str, user_id: str = "anonymous", 
                      **kwargs) -> APIResponse:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        start_time = time.time()
        
        # ìºì‹œ í™•ì¸
        use_cache = kwargs.pop('use_cache', True)
        cache_params = {'prompt': prompt, **kwargs}
        
        if use_cache:
            cached = self.cache.get(self.config.engine_type.value, cache_params)
            if cached:
                return APIResponse(
                    status=ResponseStatus.CACHED,
                    data=cached,
                    cached=True,
                    latency=time.time() - start_time
                )
        
        # Rate limit í™•ì¸
        can_call, wait_time = self.rate_limiter.check_and_add()
        if not can_call:
            return APIResponse(
                status=ResponseStatus.RATE_LIMITED,
                error=f"Rate limit ì´ˆê³¼. {wait_time:.1f}ì´ˆ í›„ ì¬ì‹œë„í•˜ì„¸ìš”.",
                metadata={'wait_time': wait_time}
            )
        
        # API í˜¸ì¶œ
        try:
            response = await self._generate_with_retry(prompt, **kwargs)
            
            # ìºì‹œ ì €ì¥
            if use_cache:
                self.cache.set(
                    self.config.engine_type.value,
                    cache_params,
                    response
                )
            
            # ì‚¬ìš©ëŸ‰ ì¶”ì 
            tokens_estimate = len(prompt.split()) + len(response.split())
            await self.usage_tracker.track(APIUsage(
                api_id=self.config.engine_type.value,
                user_id=user_id,
                timestamp=datetime.now(),
                tokens_used=tokens_estimate,
                success=True,
                latency=time.time() - start_time
            ))
            
            return APIResponse(
                status=ResponseStatus.SUCCESS,
                data=response,
                latency=time.time() - start_time,
                metadata={
                    'model': self.config.model_name,
                    'temperature': kwargs.get('temperature', self.config.temperature)
                }
            )
            
        except Exception as e:
            logger.error(f"{self.config.engine_type.value} ì˜¤ë¥˜: {e}")
            
            # ì‚¬ìš©ëŸ‰ ì¶”ì  (ì‹¤íŒ¨)
            await self.usage_tracker.track(APIUsage(
                api_id=self.config.engine_type.value,
                user_id=user_id,
                timestamp=datetime.now(),
                success=False,
                error_type=type(e).__name__,
                latency=time.time() - start_time
            ))
            
            return APIResponse(
                status=ResponseStatus.ERROR,
                error=str(e),
                latency=time.time() - start_time
            )
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10)
    )
    async def _generate_with_retry(self, prompt: str, **kwargs) -> str:
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ API í˜¸ì¶œ"""
        return await self._generate_response(prompt, **kwargs)
    
    async def _generate_response(self, prompt: str, **kwargs) -> str:
        """ì‹¤ì œ API í˜¸ì¶œ (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        raise NotImplementedError


# ============================================================================
# AI ì—”ì§„ êµ¬í˜„ì²´
# ============================================================================

class GeminiEngine(BaseAIEngine):
    """Google Gemini AI ì—”ì§„"""
    
    def __init__(self):
        super().__init__(APIConfig(
            engine_type=AIEngineType.GEMINI,
            model_name="gemini-2.0-flash-exp",
            api_key_id="gemini",
            max_tokens=8192,
            temperature=0.9,
            features=["text", "code", "vision", "function_calling"]
        ))
    
    def _init_client(self):
        """Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if GEMINI_AVAILABLE:
            genai.configure(api_key=self.config.api_key_id)
            self.client = genai.GenerativeModel(self.config.model_name)
    
    async def _generate_response(self, prompt: str, **kwargs) -> str:
        """Gemini API í˜¸ì¶œ"""
        if not self.client:
            raise Exception("Gemini í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        generation_config = genai.types.GenerationConfig(
            temperature=kwargs.get('temperature', self.config.temperature),
            max_output_tokens=kwargs.get('max_tokens', self.config.max_tokens),
            top_p=kwargs.get('top_p', 0.95)
        )
        
        response = await asyncio.to_thread(
            self.client.generate_content,
            prompt,
            generation_config=generation_config
        )
        
        return response.text


class GrokEngine(BaseAIEngine):
    """xAI Grok ì—”ì§„"""
    
    def __init__(self):
        super().__init__(APIConfig(
            engine_type=AIEngineType.GROK,
            model_name="grok-2-latest",
            api_key_id="grok",
            max_tokens=131072,
            features=["text", "code", "real_time_info"]
        ))
    
    def _init_client(self):
        """Grok í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if OPENAI_AVAILABLE:
            self.client = AsyncOpenAI(
                api_key=self.config.api_key_id,
                base_url="https://api.x.ai/v1"
            )
    
    async def _generate_response(self, prompt: str, **kwargs) -> str:
        """Grok API í˜¸ì¶œ"""
        if not self.client:
            raise Exception("Grok í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        response = await self.client.chat.completions.create(
            model=self.config.model_name,
            messages=[
                {"role": "system", "content": "You are an expert in polymer science and experimental design."},
                {"role": "user", "content": prompt}
            ],
            temperature=kwargs.get('temperature', self.config.temperature),
            max_tokens=kwargs.get('max_tokens', self.config.max_tokens)
        )
        
        return response.choices[0].message.content


class GroqEngine(BaseAIEngine):
    """Groq ì´ˆê³ ì† ì¶”ë¡  ì—”ì§„"""
    
    def __init__(self):
        super().__init__(APIConfig(
            engine_type=AIEngineType.GROQ,
            model_name="llama-3.1-70b-versatile",
            api_key_id="groq",
            max_tokens=8192,
            features=["ultra_fast", "streaming", "batch_processing"]
        ))
    
    def _init_client(self):
        """Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if GROQ_AVAILABLE:
            self.client = AsyncGroq(api_key=self.config.api_key_id)
    
    async def _generate_response(self, prompt: str, **kwargs) -> str:
        """Groq API í˜¸ì¶œ"""
        if not self.client:
            raise Exception("Groq í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        response = await self.client.chat.completions.create(
            model=self.config.model_name,
            messages=[
                {"role": "system", "content": "You are an expert in polymer science."},
                {"role": "user", "content": prompt}
            ],
            temperature=kwargs.get('temperature', self.config.temperature),
            max_tokens=kwargs.get('max_tokens', self.config.max_tokens)
        )
        
        return response.choices[0].message.content


class SambaNovaEngine(BaseAIEngine):
    """SambaNova ëŒ€ê·œëª¨ ëª¨ë¸ ì—”ì§„"""
    
    def __init__(self):
        super().__init__(APIConfig(
            engine_type=AIEngineType.SAMBANOVA,
            model_name="llama-3.1-405b",
            api_key_id="sambanova",
            max_tokens=4096,
            features=["large_scale", "stable", "enterprise"]
        ))
    
    def _init_client(self):
        """SambaNova í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if OPENAI_AVAILABLE:
            self.client = AsyncOpenAI(
                api_key=self.config.api_key_id,
                base_url="https://api.sambanova.ai/v1"
            )
    
    async def _generate_response(self, prompt: str, **kwargs) -> str:
        """SambaNova API í˜¸ì¶œ"""
        if not self.client:
            raise Exception("SambaNova í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        response = await self.client.chat.completions.create(
            model=self.config.model_name,
            messages=[
                {"role": "system", "content": "You are an expert in materials science."},
                {"role": "user", "content": prompt}
            ],
            temperature=kwargs.get('temperature', self.config.temperature),
            max_tokens=kwargs.get('max_tokens', self.config.max_tokens)
        )
        
        return response.choices[0].message.content


class DeepSeekEngine(BaseAIEngine):
    """DeepSeek ìˆ˜í•™/ì½”ë“œ íŠ¹í™” ì—”ì§„"""
    
    def __init__(self):
        super().__init__(APIConfig(
            engine_type=AIEngineType.DEEPSEEK,
            model_name="deepseek-chat",
            api_key_id="deepseek",
            max_tokens=16384,
            features=["math", "code", "formula"]
        ))
    
    def _init_client(self):
        """DeepSeek í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if OPENAI_AVAILABLE:
            self.client = AsyncOpenAI(
                api_key=self.config.api_key_id,
                base_url="https://api.deepseek.com/v1"
            )
    
    async def _generate_response(self, prompt: str, **kwargs) -> str:
        """DeepSeek API í˜¸ì¶œ"""
        if not self.client:
            raise Exception("DeepSeek í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        response = await self.client.chat.completions.create(
            model=self.config.model_name,
            messages=[
                {"role": "system", "content": "You are an expert in mathematical modeling and polymer calculations."},
                {"role": "user", "content": prompt}
            ],
            temperature=kwargs.get('temperature', self.config.temperature),
            max_tokens=kwargs.get('max_tokens', self.config.max_tokens)
        )
        
        return response.choices[0].message.content


class HuggingFaceEngine(BaseAIEngine):
    """HuggingFace íŠ¹ìˆ˜ ëª¨ë¸ ì—”ì§„"""
    
    def __init__(self):
        super().__init__(APIConfig(
            engine_type=AIEngineType.HUGGINGFACE,
            model_name="microsoft/ChemBERTa-77M",
            api_key_id="huggingface",
            features=["chemistry", "materials", "local_inference"]
        ))
        self.pipeline = None
    
    def _init_client(self):
        """HuggingFace íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        if HUGGINGFACE_AVAILABLE:
            try:
                self.pipeline = pipeline(
                    "text-generation",
                    model=self.config.model_name,
                    device=0 if torch.cuda.is_available() else -1
                )
            except Exception as e:
                logger.warning(f"ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, API ì‚¬ìš©: {e}")
                # API í´ë°±
                self.use_api = True
    
    async def _generate_response(self, prompt: str, **kwargs) -> str:
        """HuggingFace ëª¨ë¸ ì¶”ë¡ """
        if self.pipeline:
            # ë¡œì»¬ ì¶”ë¡ 
            result = await asyncio.to_thread(
                self.pipeline,
                prompt,
                max_length=kwargs.get('max_tokens', 512),
                temperature=kwargs.get('temperature', self.config.temperature)
            )
            return result[0]['generated_text']
        else:
            # API ì‚¬ìš©
            async with aiohttp.ClientSession() as session:
                headers = {"Authorization": f"Bearer {self.config.api_key_id}"}
                data = {
                    "inputs": prompt,
                    "parameters": {
                        "max_length": kwargs.get('max_tokens', 512),
                        "temperature": kwargs.get('temperature', self.config.temperature)
                    }
                }
                
                async with session.post(
                    f"https://api-inference.huggingface.co/models/{self.config.model_name}",
                    headers=headers,
                    json=data
                ) as response:
                    result = await response.json()
                    return result[0]['generated_text']


# ============================================================================
# ê³¼í•™ ë°ì´í„°ë² ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸
# ============================================================================

class ScienceDBClient:
    """ê³¼í•™ ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        self.clients = {}
        self.cache = ResponseCache(ttl=86400)  # 24ì‹œê°„ ìºì‹œ
        self._initialize_clients()
    
    def _initialize_clients(self):
        """ê° DB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        # Materials Project
        if MATERIALS_PROJECT_AVAILABLE:
            mp_key = self._get_api_key('materials_project')
            if mp_key:
                try:
                    self.clients['materials_project'] = MPRester(mp_key)
                    logger.info("Materials Project í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
                except Exception as e:
                    logger.error(f"Materials Project ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # PubChem
        if PUBCHEM_AVAILABLE:
            self.clients['pubchem'] = pcp  # API í‚¤ ë¶ˆí•„ìš”
            logger.info("PubChem í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        # GitHub
        if GITHUB_AVAILABLE:
            github_token = self._get_api_key('github')
            if github_token:
                try:
                    self.clients['github'] = Github(github_token)
                    logger.info("GitHub í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
                except Exception as e:
                    logger.error(f"GitHub ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _get_api_key(self, service: str) -> Optional[str]:
        """API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
        # í™˜ê²½ ë³€ìˆ˜
        key = os.environ.get(f"{service.upper()}_API_KEY")
        if key:
            return key
        
        # Streamlit secrets
        if hasattr(st, 'secrets'):
            try:
                key = st.secrets.get(f"{service}_api_key")
                if key:
                    return key
            except:
                pass
        
        # ì„¸ì…˜ ìƒíƒœ
        if hasattr(st, 'session_state') and 'api_keys' in st.session_state:
            key = st.session_state.api_keys.get(service)
            if key:
                return key
        
        return None
    
    async def search_materials(self, formula: str = None, 
                             material_id: str = None,
                             properties: List[str] = None) -> List[Dict]:
        """ì¬ë£Œ ê²€ìƒ‰"""
        if 'materials_project' not in self.clients:
            return []
        
        # ìºì‹œ í™•ì¸
        cache_key = {'formula': formula, 'material_id': material_id, 'properties': properties}
        cached = self.cache.get('materials_project', cache_key)
        if cached:
            return cached
        
        try:
            mp = self.clients['materials_project']
            
            # ê²€ìƒ‰ ì‹¤í–‰
            if material_id:
                results = [mp.get_structure_by_material_id(material_id)]
            elif formula:
                results = mp.get_structures(formula)
            else:
                return []
            
            # ì†ì„± ì¡°íšŒ
            materials = []
            for structure in results[:10]:  # ìµœëŒ€ 10ê°œ
                material = {
                    'formula': structure.composition.reduced_formula,
                    'crystal_system': structure.get_space_group_info()[0],
                    'volume': structure.volume,
                    'density': structure.density
                }
                
                if properties:
                    # ì¶”ê°€ ì†ì„± ì¡°íšŒ
                    props = mp.get_data(structure.composition.reduced_formula, 
                                       prop=properties)
                    if props:
                        material.update(props[0])
                
                materials.append(material)
            
            # ìºì‹œ ì €ì¥
            self.cache.set('materials_project', cache_key, materials)
            
            return materials
            
        except Exception as e:
            logger.error(f"Materials Project ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def search_compounds(self, name: str = None, 
                             formula: str = None,
                             smiles: str = None) -> List[Dict]:
        """í™”í•©ë¬¼ ê²€ìƒ‰"""
        if 'pubchem' not in self.clients:
            return []
        
        # ìºì‹œ í™•ì¸
        cache_key = {'name': name, 'formula': formula, 'smiles': smiles}
        cached = self.cache.get('pubchem', cache_key)
        if cached:
            return cached
        
        try:
            compounds = []
            
            if name:
                results = pcp.get_compounds(name, 'name')
            elif formula:
                results = pcp.get_compounds(formula, 'formula')
            elif smiles:
                results = pcp.get_compounds(smiles, 'smiles')
            else:
                return []
            
            for compound in results[:10]:  # ìµœëŒ€ 10ê°œ
                compounds.append({
                    'cid': compound.cid,
                    'name': compound.iupac_name or compound.synonyms[0] if compound.synonyms else 'Unknown',
                    'formula': compound.molecular_formula,
                    'weight': compound.molecular_weight,
                    'smiles': compound.canonical_smiles,
                    'inchi': compound.inchi
                })
            
            # ìºì‹œ ì €ì¥
            self.cache.set('pubchem', cache_key, compounds)
            
            return compounds
            
        except Exception as e:
            logger.error(f"PubChem ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def search_github_data(self, query: str, 
                               language: str = "Python") -> List[Dict]:
        """GitHub ê³¼í•™ ë°ì´í„° ê²€ìƒ‰"""
        if 'github' not in self.clients:
            return []
        
        try:
            github = self.clients['github']
            
            # ê³¼í•™ ê´€ë ¨ ë¦¬í¬ì§€í† ë¦¬ ê²€ìƒ‰
            search_query = f"{query} polymer materials science data language:{language}"
            results = github.search_repositories(query=search_query, sort='stars')
            
            repos = []
            for repo in results[:10]:  # ìµœëŒ€ 10ê°œ
                repos.append({
                    'name': repo.full_name,
                    'description': repo.description,
                    'url': repo.html_url,
                    'stars': repo.stargazers_count,
                    'language': repo.language,
                    'updated': repo.updated_at.isoformat() if repo.updated_at else None
                })
            
            return repos
            
        except Exception as e:
            logger.error(f"GitHub ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []


# ============================================================================
# ë©”ì¸ API ê´€ë¦¬ì
# ============================================================================

class APIManager:
    """í†µí•© API ê´€ë¦¬ì"""
    
    def __init__(self):
        self.ai_engines = {}
        self.db_client = None
        self.usage_tracker = defaultdict(list)
        self.encryption_manager = EncryptionManager()
        self._initialize()
    
    def _initialize(self):
        """ê´€ë¦¬ì ì´ˆê¸°í™”"""
        # AI ì—”ì§„ ì´ˆê¸°í™”
        self._init_ai_engines()
        
        # ë°ì´í„°ë² ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.db_client = ScienceDBClient()
        
        logger.info("API Manager ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_ai_engines(self):
        """AI ì—”ì§„ ì´ˆê¸°í™”"""
        engines = [
            (AIEngineType.GEMINI, GeminiEngine),
            (AIEngineType.GROK, GrokEngine),
            (AIEngineType.GROQ, GroqEngine),
            (AIEngineType.SAMBANOVA, SambaNovaEngine),
            (AIEngineType.DEEPSEEK, DeepSeekEngine),
            (AIEngineType.HUGGINGFACE, HuggingFaceEngine)
        ]
        
        for engine_type, engine_class in engines:
            try:
                engine = engine_class()
                if engine.is_available:
                    self.ai_engines[engine_type.value] = engine
                    logger.info(f"{engine_type.value} ì—”ì§„ ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                logger.warning(f"{engine_type.value} ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    # ============================================================================
    # API í‚¤ ê´€ë¦¬
    # ============================================================================
    
    def set_api_key(self, service: str, key: str) -> bool:
        """API í‚¤ ì„¤ì •"""
        try:
            # ì•”í˜¸í™” ì €ì¥
            encrypted = self.encryption_manager.encrypt(key)
            
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            if 'api_keys' not in st.session_state:
                st.session_state.api_keys = {}
            st.session_state.api_keys[service] = encrypted
            
            # ì—”ì§„ ì¬ì´ˆê¸°í™”
            if service in [e.value for e in AIEngineType]:
                self._init_ai_engines()
            elif service in ['materials_project', 'github']:
                self.db_client._initialize_clients()
            
            logger.info(f"{service} API í‚¤ ì„¤ì • ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}")
            return False
    
    def remove_api_key(self, service: str):
        """API í‚¤ ì œê±°"""
        if hasattr(st, 'session_state') and 'api_keys' in st.session_state:
            if service in st.session_state.api_keys:
                del st.session_state.api_keys[service]
    
    def get_configured_services(self) -> Dict[str, bool]:
        """ì„¤ì •ëœ ì„œë¹„ìŠ¤ ëª©ë¡"""
        services = {}
        
        # AI ì—”ì§„
        for engine_type in AIEngineType:
            services[engine_type.value] = engine_type.value in self.ai_engines
        
        # ë°ì´í„°ë² ì´ìŠ¤
        if self.db_client:
            for db_name in ['materials_project', 'pubchem', 'github']:
                services[db_name] = db_name in self.db_client.clients
        
        return services
    
    # ============================================================================
    # AI ì—”ì§„ ë©”ì„œë“œ
    # ============================================================================
    
    def get_available_engines(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ AI ì—”ì§„ ëª©ë¡"""
        return list(self.ai_engines.keys())
    
    async def generate_text(self, engine_id: str, prompt: str, 
                          user_id: str = "anonymous", **kwargs) -> APIResponse:
        """AI í…ìŠ¤íŠ¸ ìƒì„±"""
        if engine_id not in self.ai_engines:
            # í´ë°±: ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ì—”ì§„ ì‚¬ìš©
            available = self.get_available_engines()
            if available:
                engine_id = available[0]
                logger.info(f"{engine_id} ì—”ì§„ìœ¼ë¡œ í´ë°±")
            else:
                return APIResponse(
                    status=ResponseStatus.ERROR,
                    error="ì‚¬ìš© ê°€ëŠ¥í•œ AI ì—”ì§„ì´ ì—†ìŠµë‹ˆë‹¤."
                )
        
        engine = self.ai_engines[engine_id]
        response = await engine.generate(prompt, user_id, **kwargs)
        
        # ì‚¬ìš©ëŸ‰ ê¸°ë¡
        self.usage_tracker[engine_id].append({
            'user_id': user_id,
            'timestamp': datetime.now(),
            'success': response.status == ResponseStatus.SUCCESS
        })
        
        return response
    
    async def analyze_experiment(self, engine_id: str, 
                               experiment_data: Dict,
                               user_id: str = "anonymous") -> APIResponse:
        """ì‹¤í—˜ ë°ì´í„° ë¶„ì„"""
        prompt = f"""
        ë‹¤ìŒ ì‹¤í—˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
        
        ì‹¤í—˜ ìœ í˜•: {experiment_data.get('type', 'ì•Œ ìˆ˜ ì—†ìŒ')}
        ìš”ì¸: {experiment_data.get('factors', [])}
        ë°˜ì‘ë³€ìˆ˜: {experiment_data.get('responses', [])}
        ê²°ê³¼: {experiment_data.get('results', {})}
        
        1. ì£¼ìš” ë°œê²¬ì‚¬í•­
        2. í†µê³„ì  ìœ ì˜ì„±
        3. ìµœì  ì¡°ê±´
        4. ê°œì„  ì œì•ˆ
        """
        
        return await self.generate_text(engine_id, prompt, user_id, 
                                      temperature=0.5)  # ë¶„ì„ì€ ë‚®ì€ ì˜¨ë„
    
    async def suggest_next_experiment(self, engine_id: str,
                                    current_results: Dict,
                                    user_id: str = "anonymous") -> APIResponse:
        """ë‹¤ìŒ ì‹¤í—˜ ì œì•ˆ"""
        prompt = f"""
        í˜„ì¬ê¹Œì§€ì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì‹¤í—˜ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:
        
        ì™„ë£Œëœ ì‹¤í—˜: {current_results.get('completed_runs', 0)}
        í˜„ì¬ ìµœì ê°’: {current_results.get('current_optimum', {})}
        íƒìƒ‰ëœ ì˜ì—­: {current_results.get('explored_region', [])}
        
        ì œì•ˆ í˜•ì‹:
        1. ì¶”ì²œí•˜ëŠ” ë‹¤ìŒ ì‹¤í—˜ ì¡°ê±´
        2. ê¸°ëŒ€ë˜ëŠ” ê°œì„  ì •ë„
        3. ìœ„í—˜ ìš”ì†Œ
        4. ëŒ€ì•ˆì  ì ‘ê·¼ë²•
        """
        
        return await self.generate_text(engine_id, prompt, user_id,
                                      temperature=0.7)
    
    # ============================================================================
    # ë°ì´í„°ë² ì´ìŠ¤ ë©”ì„œë“œ
    # ============================================================================
    
    async def search_materials(self, **kwargs) -> List[Dict]:
        """ì¬ë£Œ ê²€ìƒ‰"""
        if not self.db_client:
            return []
        return await self.db_client.search_materials(**kwargs)
    
    async def search_compounds(self, **kwargs) -> List[Dict]:
        """í™”í•©ë¬¼ ê²€ìƒ‰"""
        if not self.db_client:
            return []
        return await self.db_client.search_compounds(**kwargs)
    
    async def search_github_data(self, **kwargs) -> List[Dict]:
        """GitHub ë°ì´í„° ê²€ìƒ‰"""
        if not self.db_client:
            return []
        return await self.db_client.search_github_data(**kwargs)
    
    # ============================================================================
    # ì‚¬ìš©ëŸ‰ ë° ìƒíƒœ ê´€ë¦¬
    # ============================================================================
    
    def get_usage_summary(self, user_id: Optional[str] = None,
                         period: str = 'day') -> Dict[str, Dict]:
        """ì‚¬ìš©ëŸ‰ ìš”ì•½"""
        summary = {}
        
        # AI ì—”ì§„ë³„ ì‚¬ìš©ëŸ‰
        for engine_id, engine in self.ai_engines.items():
            summary[engine_id] = engine.usage_tracker.get_usage_summary(user_id, period)
        
        return summary
    
    def get_rate_limit_status(self) -> Dict[str, Dict]:
        """Rate limit ìƒíƒœ"""
        status = {}
        
        for engine_id, engine in self.ai_engines.items():
            if engine.rate_limiter:
                status[engine_id] = engine.rate_limiter.get_remaining()
        
        return status
    
    def clear_cache(self, cache_type: Optional[str] = None):
        """ìºì‹œ ì´ˆê¸°í™”"""
        # AI ì—”ì§„ ìºì‹œ
        for engine in self.ai_engines.values():
            engine.cache.clear(cache_type)
        
        # DB í´ë¼ì´ì–¸íŠ¸ ìºì‹œ
        if self.db_client:
            self.db_client.cache.clear(cache_type)
        
        logger.info(f"ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ: {cache_type or 'ì „ì²´'}")
    
    def get_api_status(self) -> Dict[str, Any]:
        """ì „ì²´ API ìƒíƒœ"""
        return {
            'ai_engines': {
                engine_id: {
                    'available': True,
                    'model': engine.config.model_name,
                    'features': engine.config.features,
                    'rate_limit': engine.rate_limiter.get_remaining() if engine.rate_limiter else None
                }
                for engine_id, engine in self.ai_engines.items()
            },
            'databases': self.get_configured_services(),
            'total_available': len(self.ai_engines) + len(self.db_client.clients if self.db_client else {})
        }


# ============================================================================
# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
# ============================================================================

_api_manager: Optional[APIManager] = None


def get_api_manager() -> APIManager:
    """APIManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _api_manager
    
    if _api_manager is None:
        _api_manager = APIManager()
    
    return _api_manager


# ============================================================================
# í—¬í¼ í•¨ìˆ˜
# ============================================================================

async def ask_ai(prompt: str, engine: str = "gemini", 
                user_id: str = "anonymous", **kwargs) -> str:
    """ê°„í¸ AI ì§ˆë¬¸ í•¨ìˆ˜"""
    manager = get_api_manager()
    response = await manager.generate_text(engine, prompt, user_id, **kwargs)
    
    if response.status == ResponseStatus.SUCCESS:
        return response.data
    else:
        return f"ì˜¤ë¥˜: {response.error}"


async def analyze_experiment_data(data: Dict, user_id: str = "anonymous") -> Dict:
    """ê°„í¸ ì‹¤í—˜ ë¶„ì„ í•¨ìˆ˜"""
    manager = get_api_manager()
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ì—”ì§„ ì‚¬ìš©
    engines = manager.get_available_engines()
    if not engines:
        return {"error": "ì‚¬ìš© ê°€ëŠ¥í•œ AI ì—”ì§„ì´ ì—†ìŠµë‹ˆë‹¤"}
    
    response = await manager.analyze_experiment(engines[0], data, user_id)
    
    if response.status == ResponseStatus.SUCCESS:
        return {"analysis": response.data}
    else:
        return {"error": response.error}


def render_api_status_card():
    """API ìƒíƒœ ì¹´ë“œ ë Œë”ë§"""
    manager = get_api_manager()
    status = manager.get_api_status()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "í™œì„± AI ì—”ì§„",
            len(status['ai_engines']),
            delta=f"/{len(AIEngineType)}"
        )
    
    with col2:
        active_dbs = sum(1 for v in status['databases'].values() if v)
        st.metric(
            "ì—°ê²°ëœ DB",
            active_dbs,
            delta=f"/{len(status['databases'])}"
        )
    
    with col3:
        st.metric(
            "ì „ì²´ API",
            status['total_available'],
            delta="í™œì„±"
        )


def render_api_configuration():
    """API ì„¤ì • UI"""
    st.subheader("ğŸ”‘ API ì„¤ì •")
    
    manager = get_api_manager()
    configured = manager.get_configured_services()
    
    # AI ì—”ì§„ ì„¤ì •
    with st.expander("AI ì—”ì§„ API í‚¤", expanded=False):
        for engine_type in AIEngineType:
            col1, col2 = st.columns([3, 1])
            with col1:
                key = st.text_input(
                    f"{engine_type.value.upper()} API Key",
                    type="password",
                    key=f"api_key_{engine_type.value}",
                    help=f"{engine_type.value} API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
                )
            with col2:
                if st.button("ì €ì¥", key=f"save_{engine_type.value}"):
                    if key:
                        if manager.set_api_key(engine_type.value, key):
                            show_success(f"{engine_type.value} API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        else:
                            show_error("API í‚¤ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
                status = "âœ…" if configured.get(engine_type.value) else "âŒ"
                st.write(f"ìƒíƒœ: {status}")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
    with st.expander("ê³¼í•™ ë°ì´í„°ë² ì´ìŠ¤ API í‚¤", expanded=False):
        db_services = ['materials_project', 'github']
        for service in db_services:
            col1, col2 = st.columns([3, 1])
            with col1:
                key = st.text_input(
                    f"{service.replace('_', ' ').title()} API Key",
                    type="password",
                    key=f"api_key_{service}",
                    help=f"{service} API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
                )
            with col2:
                if st.button("ì €ì¥", key=f"save_{service}"):
                    if key:
                        if manager.set_api_key(service, key):
                            show_success(f"{service} API í‚¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        else:
                            show_error("API í‚¤ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
                status = "âœ…" if configured.get(service) else "âŒ"
                st.write(f"ìƒíƒœ: {status}")
