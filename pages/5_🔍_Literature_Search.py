"""
Literature Search Page - í†µí•© ì—°êµ¬ ìì› ê²€ìƒ‰ (Full API Implementation)
ëª¨ë“  ì™¸ë¶€ APIë¥¼ ì‹¤ì œë¡œ ì—°ë™í•˜ëŠ” ì™„ì „í•œ êµ¬í˜„ ë²„ì „
"""

import streamlit as st
import pandas as pd
import numpy as np
import requests
import json
import re
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Set
from concurrent.futures import ThreadPoolExecutor, as_completed
import plotly.graph_objects as go
import plotly.express as px
from io import BytesIO
import PyPDF2
import fitz  # PyMuPDF
import time
import aiohttp
from urllib.parse import quote, urlencode
import xml.etree.ElementTree as ET

# í•™ìˆ  ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from pymatgen.ext.matproj import MPRester  # Materials Project
    MATPROJ_AVAILABLE = True
except ImportError:
    MATPROJ_AVAILABLE = False
    
try:
    import arxiv
    ARXIV_AVAILABLE = True
except ImportError:
    ARXIV_AVAILABLE = False
    
try:
    from github import Github
    GITHUB_AVAILABLE = True
except ImportError:
    GITHUB_AVAILABLE = False

# ë‚´ë¶€ ëª¨ë“ˆ
from utils.auth_manager import check_authentication, get_current_user
from utils.sheets_manager import GoogleSheetsManager
from utils.api_manager import APIManager
from utils.common_ui import get_common_ui
from utils.notification_manager import NotificationManager
from utils.secrets_manager import get_secrets_manager

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Literature Search - Universal DOE",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì¸ì¦ ì²´í¬
if not check_authentication():
    st.error("ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

class IntegratedResearchManager:
    """í†µí•© ì—°êµ¬ ìì› ê´€ë¦¬ í´ë˜ìŠ¤ - ëª¨ë“  API ì‹¤ì œ êµ¬í˜„"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.sheets = GoogleSheetsManager()
        self.api = APIManager()
        self.notifier = NotificationManager()
        self.ui = get_common_ui()
        self.secrets = get_secrets_manager()
        self.current_user = get_current_user()
        
        # API ì—”ë“œí¬ì¸íŠ¸
        self.api_endpoints = {
            'openalex': 'https://api.openalex.org',
            'crossref': 'https://api.crossref.org',
            'uspto': 'https://developer.uspto.gov/patentservice/v1',
            'zenodo': 'https://zenodo.org/api',
            'protocols_io': 'https://www.protocols.io/api/v3',
            'pubchem': 'https://pubchem.ncbi.nlm.nih.gov/rest/pug',
            'chemspider': 'http://www.chemspider.com/JSON.ashx'
        }
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        self._init_session_state()
        
        # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self._init_api_clients()
        
    def _init_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'search_results' not in st.session_state:
            st.session_state.search_results = None
        if 'saved_searches' not in st.session_state:
            st.session_state.saved_searches = []
        if 'show_ai_details' not in st.session_state:
            st.session_state.show_ai_details = False
        if 'current_project' not in st.session_state:
            st.session_state.current_project = None
            
    def _init_api_clients(self):
        """ì™¸ë¶€ API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        # GitHub
        self.github_client = None
        if GITHUB_AVAILABLE:
            github_token = self.secrets.get_api_key('github')
            if github_token:
                try:
                    self.github_client = Github(github_token)
                except Exception as e:
                    st.warning(f"GitHub API ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        
        # Materials Project
        self.mp_client = None
        if MATPROJ_AVAILABLE:
            mp_api_key = self.secrets.get_api_key('materials_project')
            if mp_api_key:
                try:
                    self.mp_client = MPRester(mp_api_key)
                except Exception as e:
                    st.warning(f"Materials Project API ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        
        # Zenodo
        self.zenodo_token = self.secrets.get_api_key('zenodo')
        
        # protocols.io
        self.protocols_token = self.secrets.get_api_key('protocols_io')
    
    # === ë©”ì¸ ë Œë”ë§ ë©”ì„œë“œ (ì´ì „ê³¼ ë™ì¼) ===
    def render_page(self):
        """ë©”ì¸ í˜ì´ì§€ ë Œë”ë§"""
        # í—¤ë”
        self.ui.render_header(
            "ğŸ” í†µí•© ì—°êµ¬ ìì› ê²€ìƒ‰",
            "ë¬¸í—Œ, í”„ë¡œí† ì½œ, ì‹¤í—˜ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ê²€ìƒ‰í•˜ê³  AIë¡œ ë¶„ì„í•˜ì„¸ìš”"
        )
        
        # ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤
        self._render_search_interface()
        
        # ê²€ìƒ‰ ê²°ê³¼ ë˜ëŠ” ìµœê·¼ í™œë™
        if st.session_state.search_results:
            self._render_search_results()
        else:
            col1, col2 = st.columns(2)
            with col1:
                self._render_recent_searches()
            with col2:
                self._render_saved_resources()
    
    # === ì‹¤ì œ API êµ¬í˜„ ë¶€ë¶„ ===
    
    def _search_openalex(self, query: str, filters: Dict) -> List[Dict]:
        """OpenAlex APIë¥¼ í†µí•œ í•™ìˆ  ë¬¸í—Œ ê²€ìƒ‰ (Google Scholar ëŒ€ì²´)"""
        results = []
        
        try:
            # API íŒŒë¼ë¯¸í„° êµ¬ì„±
            params = {
                'search': query,
                'filter': self._build_openalex_filters(filters),
                'per_page': 25,
                'page': 1
            }
            
            # ê³ ë¶„ì ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
            if filters.get('polymer_types'):
                params['search'] += ' ' + ' '.join(filters['polymer_types'])
            
            # API í˜¸ì¶œ
            response = requests.get(
                f"{self.api_endpoints['openalex']}/works",
                params=params,
                headers={'User-Agent': 'Universal-DOE-Platform/1.0'}
            )
            
            if response.status_code == 200:
                data = response.json()
                
                for work in data.get('results', []):
                    # í•„í„°ë§
                    if filters.get('min_citations', 0) > 0:
                        if work.get('cited_by_count', 0) < filters['min_citations']:
                            continue
                    
                    # ì €ì ì •ë³´ ì¶”ì¶œ
                    authors = []
                    for authorship in work.get('authorships', []):
                        author = authorship.get('author', {})
                        if author.get('display_name'):
                            authors.append(author['display_name'])
                    
                    # ê²°ê³¼ í¬ë§·íŒ…
                    results.append({
                        'id': work.get('id', '').split('/')[-1],
                        'type': 'paper',
                        'title': work.get('display_name', ''),
                        'authors': authors[:5],  # ìµœëŒ€ 5ëª…
                        'year': work.get('publication_year'),
                        'abstract': work.get('abstract_inverted_index', ''),  # ì²˜ë¦¬ í•„ìš”
                        'citations': work.get('cited_by_count', 0),
                        'doi': work.get('doi', ''),
                        'url': work.get('doi', '').replace('https://doi.org/', 'https://doi.org/') if work.get('doi') else '',
                        'open_access': work.get('open_access', {}).get('is_oa', False),
                        'pdf_url': work.get('open_access', {}).get('oa_url', ''),
                        'source': 'OpenAlex',
                        'journal': work.get('host_venue', {}).get('display_name', ''),
                        'concepts': [c['display_name'] for c in work.get('concepts', [])[:5]]
                    })
            else:
                st.warning(f"OpenAlex API ì˜¤ë¥˜: {response.status_code}")
                
        except Exception as e:
            st.error(f"OpenAlex ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    def _search_crossref(self, query: str, filters: Dict) -> List[Dict]:
        """Crossref APIë¥¼ í†µí•œ í•™ìˆ  ë¬¸í—Œ ê²€ìƒ‰"""
        results = []
        
        try:
            # API íŒŒë¼ë¯¸í„° êµ¬ì„±
            params = {
                'query': query,
                'rows': 20,
                'filter': self._build_crossref_filters(filters),
                'sort': 'relevance',
                'order': 'desc'
            }
            
            # API í˜¸ì¶œ
            response = requests.get(
                f"{self.api_endpoints['crossref']}/works",
                params=params
            )
            
            if response.status_code == 200:
                data = response.json()
                
                for item in data.get('message', {}).get('items', []):
                    # ì €ì ì¶”ì¶œ
                    authors = []
                    for author in item.get('author', []):
                        name = f"{author.get('given', '')} {author.get('family', '')}".strip()
                        if name:
                            authors.append(name)
                    
                    # ë‚ ì§œ ì²˜ë¦¬
                    published = item.get('published-print') or item.get('published-online')
                    year = None
                    if published and 'date-parts' in published:
                        try:
                            year = published['date-parts'][0][0]
                        except:
                            pass
                    
                    results.append({
                        'id': item.get('DOI', ''),
                        'type': 'paper',
                        'title': item.get('title', [''])[0],
                        'authors': authors[:5],
                        'year': year,
                        'abstract': item.get('abstract', ''),
                        'citations': item.get('is-referenced-by-count', 0),
                        'doi': item.get('DOI', ''),
                        'url': f"https://doi.org/{item.get('DOI', '')}",
                        'source': 'Crossref',
                        'journal': item.get('container-title', [''])[0],
                        'publisher': item.get('publisher', ''),
                        'subjects': item.get('subject', [])
                    })
            else:
                st.warning(f"Crossref API ì˜¤ë¥˜: {response.status_code}")
                
        except Exception as e:
            st.error(f"Crossref ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    def _search_patents(self, query: str, filters: Dict) -> List[Dict]:
        """USPTO APIë¥¼ í†µí•œ íŠ¹í—ˆ ê²€ìƒ‰"""
        results = []
        
        try:
            # USPTO APIëŠ” ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‚¬ìš©
            # ì‹¤ì œë¡œëŠ” PatentsView APIê°€ ë” ì¢‹ìŒ
            params = {
                'q': f'_text_any:{query} AND polymer',
                'f': '["patent_number","patent_title","patent_abstract","patent_date","inventor_last_name"]',
                'o': '{"per_page":20}'
            }
            
            response = requests.get(
                'https://api.patentsview.org/patents/query',
                params=params
            )
            
            if response.status_code == 200:
                data = response.json()
                
                for patent in data.get('patents', []):
                    results.append({
                        'id': patent.get('patent_number', ''),
                        'type': 'patent',
                        'title': patent.get('patent_title', ''),
                        'abstract': patent.get('patent_abstract', ''),
                        'date': patent.get('patent_date', ''),
                        'inventors': [inv.get('inventor_last_name', '') for inv in patent.get('inventors', [])[:3]],
                        'url': f"https://patents.google.com/patent/US{patent.get('patent_number', '')}",
                        'source': 'USPTO'
                    })
            
        except Exception as e:
            st.warning(f"íŠ¹í—ˆ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    def _search_protocols_io(self, query: str, filters: Dict) -> List[Dict]:
        """protocols.io APIë¥¼ í†µí•œ í”„ë¡œí† ì½œ ê²€ìƒ‰"""
        results = []
        
        if not self.protocols_token:
            return self._generate_ai_protocols(query, filters)
        
        try:
            headers = {
                'Authorization': f'Bearer {self.protocols_token}',
                'Content-Type': 'application/json'
            }
            
            params = {
                'q': query + ' polymer',
                'order_field': 'relevance',
                'order_dir': 'desc',
                'page_size': 20
            }
            
            response = requests.get(
                f"{self.api_endpoints['protocols_io']}/protocols",
                params=params,
                headers=headers
            )
            
            if response.status_code == 200:
                data = response.json()
                
                for protocol in data.get('items', []):
                    # ë‹¨ê³„ ì¶”ì¶œ
                    steps = []
                    for step in protocol.get('steps', []):
                        steps.append(step.get('description', ''))
                    
                    results.append({
                        'id': protocol.get('id', ''),
                        'type': 'protocol',
                        'title': protocol.get('title', ''),
                        'description': protocol.get('description', ''),
                        'steps': steps[:10],  # ìµœëŒ€ 10ë‹¨ê³„
                        'materials': protocol.get('materials', []),
                        'duration': protocol.get('estimated_time', ''),
                        'difficulty': protocol.get('difficulty', 'medium'),
                        'authors': [a.get('name', '') for a in protocol.get('authors', [])],
                        'url': protocol.get('uri', ''),
                        'source': 'protocols.io',
                        'reproducibility_score': 0.9  # protocols.ioëŠ” ë†’ì€ ì¬í˜„ì„±
                    })
            else:
                # API ì‹¤íŒ¨ ì‹œ AI ìƒì„±ìœ¼ë¡œ í´ë°±
                return self._generate_ai_protocols(query, filters)
                
        except Exception as e:
            st.warning(f"protocols.io ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            return self._generate_ai_protocols(query, filters)
        
        return results
    
    def _search_zenodo(self, query: str, filters: Dict) -> List[Dict]:
        """Zenodo APIë¥¼ í†µí•œ ë°ì´í„°ì…‹ ê²€ìƒ‰"""
        results = []
        
        try:
            params = {
                'q': f'{query} AND polymer',
                'type': 'dataset',
                'sort': 'mostrecent',
                'size': 20
            }
            
            # í† í°ì´ ìˆìœ¼ë©´ ì¶”ê°€
            if self.zenodo_token:
                params['access_token'] = self.zenodo_token
            
            response = requests.get(
                f"{self.api_endpoints['zenodo']}/records",
                params=params
            )
            
            if response.status_code == 200:
                data = response.json()
                
                for hit in data.get('hits', {}).get('hits', []):
                    record = hit
                    
                    # íŒŒì¼ ì •ë³´ ì¶”ì¶œ
                    files = []
                    total_size = 0
                    formats = set()
                    
                    for file in record.get('files', []):
                        files.append({
                            'name': file.get('key', ''),
                            'size': file.get('size', 0),
                            'url': file.get('links', {}).get('self', '')
                        })
                        total_size += file.get('size', 0)
                        
                        # íŒŒì¼ í˜•ì‹ ì¶”ì¶œ
                        ext = file.get('key', '').split('.')[-1].lower()
                        if ext:
                            formats.add(ext)
                    
                    results.append({
                        'id': record.get('id', ''),
                        'type': 'dataset',
                        'title': record.get('metadata', {}).get('title', ''),
                        'description': record.get('metadata', {}).get('description', ''),
                        'creators': [c.get('name', '') for c in record.get('metadata', {}).get('creators', [])],
                        'doi': record.get('doi', ''),
                        'url': record.get('links', {}).get('html', ''),
                        'files': files[:5],  # ìµœëŒ€ 5ê°œ
                        'size': total_size,
                        'formats': list(formats),
                        'keywords': record.get('metadata', {}).get('keywords', []),
                        'license': record.get('metadata', {}).get('license', {}).get('id', ''),
                        'published': record.get('metadata', {}).get('publication_date', ''),
                        'source': 'Zenodo'
                    })
            else:
                st.warning(f"Zenodo API ì˜¤ë¥˜: {response.status_code}")
                
        except Exception as e:
            st.error(f"Zenodo ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    def _search_materials_project(self, query: str, filters: Dict) -> List[Dict]:
        """Materials Project APIë¥¼ í†µí•œ ì¬ë£Œ ê²€ìƒ‰"""
        results = []
        
        if not self.mp_client:
            return self._generate_ai_materials(query, filters)
        
        try:
            # ê³ ë¶„ìëŠ” Materials Projectì— ë§ì§€ ì•Šìœ¼ë¯€ë¡œ ê´€ë ¨ ë¬´ê¸°ë¬¼/ë³µí•©ì¬ë£Œ ê²€ìƒ‰
            # ê²€ìƒ‰ì–´ì—ì„œ ì›ì†Œ ì¶”ì¶œ
            elements = self._extract_elements_from_query(query)
            
            if not elements:
                # ì¼ë°˜ì ì¸ ê³ ë¶„ì ê´€ë ¨ ì›ì†Œë“¤
                elements = ['C', 'H', 'O', 'N']
            
            # Materials Project ê²€ìƒ‰
            criteria = {
                'elements': {'$in': elements},
                'nelements': {'$lte': 6}  # ìµœëŒ€ 6ì›ì†Œ
            }
            
            properties = [
                'material_id', 'pretty_formula', 'spacegroup',
                'formation_energy_per_atom', 'band_gap', 'density',
                'elastic', 'piezo', 'diel'
            ]
            
            materials = self.mp_client.query(
                criteria=criteria,
                properties=properties,
                max_docs=20
            )
            
            for mat in materials:
                # ë¬¼ì„± ì •ë¦¬
                properties_dict = {
                    'Formation Energy': f"{mat.get('formation_energy_per_atom', 0):.3f} eV/atom",
                    'Band Gap': f"{mat.get('band_gap', 0):.2f} eV",
                    'Density': f"{mat.get('density', 0):.2f} g/cmÂ³"
                }
                
                # íƒ„ì„± íŠ¹ì„±
                if mat.get('elastic'):
                    properties_dict['Bulk Modulus'] = f"{mat['elastic'].get('K_VRH', 0):.1f} GPa"
                    properties_dict['Shear Modulus'] = f"{mat['elastic'].get('G_VRH', 0):.1f} GPa"
                
                results.append({
                    'id': mat.get('material_id', ''),
                    'type': 'material',
                    'title': mat.get('pretty_formula', ''),
                    'formula': mat.get('pretty_formula', ''),
                    'spacegroup': mat.get('spacegroup', {}).get('symbol', ''),
                    'properties': properties_dict,
                    'applications': self._suggest_applications(mat),
                    'url': f"https://materialsproject.org/materials/{mat.get('material_id', '')}",
                    'source': 'Materials Project'
                })
                
        except Exception as e:
            st.warning(f"Materials Project ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            return self._generate_ai_materials(query, filters)
        
        return results
    
    def _search_pubchem(self, query: str, filters: Dict) -> List[Dict]:
        """PubChem APIë¥¼ í†µí•œ í™”í•©ë¬¼ ê²€ìƒ‰"""
        results = []
        
        try:
            # í™”í•©ë¬¼ ê²€ìƒ‰
            search_url = f"{self.api_endpoints['pubchem']}/compound/name/{quote(query)}/cids/JSON"
            response = requests.get(search_url)
            
            if response.status_code == 200:
                cids = response.json().get('IdentifierList', {}).get('CID', [])[:10]
                
                # ê° í™”í•©ë¬¼ì˜ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                for cid in cids:
                    prop_url = f"{self.api_endpoints['pubchem']}/compound/cid/{cid}/property/MolecularFormula,MolecularWeight,CanonicalSMILES,IUPACName/JSON"
                    prop_response = requests.get(prop_url)
                    
                    if prop_response.status_code == 200:
                        props = prop_response.json().get('PropertyTable', {}).get('Properties', [{}])[0]
                        
                        results.append({
                            'id': f"pubchem_{cid}",
                            'type': 'material',
                            'title': props.get('IUPACName', f'CID {cid}'),
                            'formula': props.get('MolecularFormula', ''),
                            'properties': {
                                'Molecular Weight': f"{props.get('MolecularWeight', 0)} g/mol",
                                'SMILES': props.get('CanonicalSMILES', ''),
                                'CID': cid
                            },
                            'url': f"https://pubchem.ncbi.nlm.nih.gov/compound/{cid}",
                            'source': 'PubChem'
                        })
                        
        except Exception as e:
            st.warning(f"PubChem ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    # === ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰ (ìˆ˜ì •) ===
    def _parallel_search(self, query: str, filters: Dict, 
                        progress_bar, status_text) -> Dict:
        """ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰ - ëª¨ë“  ì‹¤ì œ API ì‚¬ìš©"""
        results = {
            'papers': [],
            'patents': [],
            'protocols': [],
            'datasets': [],
            'code': [],
            'materials': [],
            'total_count': 0
        }
        
        # ê²€ìƒ‰ ì‘ì—… ì •ì˜
        search_tasks = []
        
        # ë…¼ë¬¸ ê²€ìƒ‰
        if "ğŸ“„ ë…¼ë¬¸" in filters['resource_types']:
            if "OpenAlex" in filters['sources']:
                search_tasks.append(('openalex', self._search_openalex, query, filters))
            if "Crossref" in filters['sources']:
                search_tasks.append(('crossref', self._search_crossref, query, filters))
            if "arXiv" in filters['sources'] and ARXIV_AVAILABLE:
                search_tasks.append(('arxiv', self._search_arxiv, query, filters))
        
        # íŠ¹í—ˆ ê²€ìƒ‰
        if "ğŸ“‹ íŠ¹í—ˆ" in filters['resource_types']:
            if "Patents" in filters['sources']:
                search_tasks.append(('patents', self._search_patents, query, filters))
        
        # í”„ë¡œí† ì½œ ê²€ìƒ‰
        if "ğŸ”¬ í”„ë¡œí† ì½œ" in filters['resource_types']:
            if "protocols.io" in filters['sources']:
                search_tasks.append(('protocols', self._search_protocols_io, query, filters))
        
        # ë°ì´í„°ì…‹ ê²€ìƒ‰
        if "ğŸ“Š ì‹¤í—˜ë°ì´í„°" in filters['resource_types']:
            if "Zenodo" in filters['sources']:
                search_tasks.append(('zenodo', self._search_zenodo, query, filters))
            if "GitHub" in filters['sources'] and self.github_client:
                search_tasks.append(('github', self._search_github, query, filters))
        
        # ì½”ë“œ ê²€ìƒ‰
        if "ğŸ’» ì½”ë“œ" in filters['resource_types']:
            if "GitHub" in filters['sources'] and self.github_client:
                search_tasks.append(('github_code', self._search_github_code, query, filters))
        
        # ì¬ë£Œ ì •ë³´ ê²€ìƒ‰
        if "ğŸ§ª ì¬ë£Œì •ë³´" in filters['resource_types']:
            if "Materials Project" in filters['sources']:
                search_tasks.append(('materials', self._search_materials_project, query, filters))
            if "PubChem" in filters['sources']:
                search_tasks.append(('pubchem', self._search_pubchem, query, filters))
        
        # ë³‘ë ¬ ì‹¤í–‰
        total_tasks = len(search_tasks)
        completed = 0
        
        with ThreadPoolExecutor(max_workers=6) as executor:
            futures = {}
            
            for task_name, task_func, task_query, task_filters in search_tasks:
                future = executor.submit(task_func, task_query, task_filters)
                futures[future] = task_name
            
            for future in as_completed(futures):
                task_name = futures[future]
                completed += 1
                
                try:
                    task_results = future.result()
                    
                    # ê²°ê³¼ ë¶„ë¥˜
                    for result in task_results:
                        result_type = result.get('type', '')
                        if result_type == 'paper':
                            results['papers'].append(result)
                        elif result_type == 'patent':
                            results['patents'].append(result)
                        elif result_type == 'protocol':
                            results['protocols'].append(result)
                        elif result_type == 'dataset':
                            results['datasets'].append(result)
                        elif result_type == 'code':
                            results['code'].append(result)
                        elif result_type == 'material':
                            results['materials'].append(result)
                    
                    results['total_count'] += len(task_results)
                    
                except Exception as e:
                    st.warning(f"{task_name} ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress = int((completed / total_tasks) * 80)
                progress_bar.progress(progress)
                status_text.text(f"ê²€ìƒ‰ ì¤‘... ({completed}/{total_tasks} ì†ŒìŠ¤ ì™„ë£Œ)")
        
        return results
    
    # === í—¬í¼ ë©”ì„œë“œë“¤ ===
    
    def _build_openalex_filters(self, filters: Dict) -> str:
        """OpenAlex API í•„í„° êµ¬ì„±"""
        filter_parts = []
        
        # ë‚ ì§œ í•„í„°
        if filters.get('date_range'):
            start_date = filters['date_range'][0].strftime('%Y-%m-%d')
            end_date = filters['date_range'][1].strftime('%Y-%m-%d')
            filter_parts.append(f"from_publication_date:{start_date},to_publication_date:{end_date}")
        
        # ì˜¤í”ˆ ì•¡ì„¸ìŠ¤ í•„í„°
        if filters.get('open_access'):
            filter_parts.append("is_oa:true")
        
        # ì–¸ì–´ í•„í„° (OpenAlexëŠ” ì–¸ì–´ í•„í„°ê°€ ì œí•œì )
        if 'English' in filters.get('languages', []):
            filter_parts.append("language:en")
        
        return ','.join(filter_parts)
    
    def _build_crossref_filters(self, filters: Dict) -> str:
        """Crossref API í•„í„° êµ¬ì„±"""
        filter_parts = []
        
        # ë‚ ì§œ í•„í„°
        if filters.get('date_range'):
            start_date = filters['date_range'][0].strftime('%Y-%m-%d')
            end_date = filters['date_range'][1].strftime('%Y-%m-%d')
            filter_parts.append(f"from-pub-date:{start_date},until-pub-date:{end_date}")
        
        # íƒ€ì… í•„í„° (journal-article, book-chapter, etc.)
        filter_parts.append("type:journal-article")
        
        return ','.join(filter_parts)
    
    def _search_github_code(self, query: str, filters: Dict) -> List[Dict]:
        """GitHub ì½”ë“œ ê²€ìƒ‰ ì „ìš©"""
        results = []
        
        if not self.github_client:
            return results
        
        try:
            # ì½”ë“œ ê²€ìƒ‰ ì¿¼ë¦¬
            code_query = f"{query} polymer extension:py extension:ipynb extension:m extension:R"
            
            code_search = self.github_client.search_code(
                query=code_query,
                sort='indexed',
                order='desc'
            )
            
            for code in code_search[:15]:
                results.append({
                    'id': f"github_code_{code.sha}",
                    'type': 'code',
                    'title': code.name,
                    'repository': code.repository.full_name,
                    'path': code.path,
                    'url': code.html_url,
                    'language': code.repository.language,
                    'description': code.repository.description,
                    'stars': code.repository.stargazers_count,
                    'topics': code.repository.get_topics(),
                    'source': 'GitHub'
                })
                
        except Exception as e:
            st.warning(f"GitHub ì½”ë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    def _extract_elements_from_query(self, query: str) -> List[str]:
        """ì¿¼ë¦¬ì—ì„œ í™”í•™ ì›ì†Œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ ì›ì†Œ ì¶”ì¶œ (í–¥í›„ ê°œì„  í•„ìš”)
        common_elements = ['C', 'H', 'O', 'N', 'S', 'P', 'F', 'Cl', 'Br', 'Si']
        found_elements = []
        
        for element in common_elements:
            if element in query:
                found_elements.append(element)
        
        return found_elements if found_elements else ['C', 'H', 'O', 'N']
    
    def _suggest_applications(self, material: Dict) -> List[str]:
        """ì¬ë£Œ íŠ¹ì„± ê¸°ë°˜ ì‘ìš© ë¶„ì•¼ ì œì•ˆ"""
        applications = []
        
        band_gap = material.get('band_gap', 0)
        if band_gap > 0:
            if band_gap < 1.5:
                applications.append("íƒœì–‘ì „ì§€")
            elif band_gap > 3:
                applications.append("íˆ¬ëª… ì „ê·¹")
        
        if material.get('piezo'):
            applications.append("ì••ì „ ì†Œì")
        
        if material.get('diel'):
            applications.append("ìœ ì „ì²´")
        
        return applications if applications else ["ë³µí•©ì¬ë£Œ", "ì½”íŒ…"]
    
    def _generate_ai_protocols(self, query: str, filters: Dict) -> List[Dict]:
        """AI ê¸°ë°˜ í”„ë¡œí† ì½œ ìƒì„± (í´ë°±)"""
        results = []
        
        protocol_prompt = f"""
        ê²€ìƒ‰ì–´: {query}
        ê³ ë¶„ì ì¢…ë¥˜: {', '.join(filters.get('polymer_types', []))}
        ê´€ì‹¬ ë¬¼ì„±: {', '.join(filters.get('properties', []))}
        
        ìœ„ ì¡°ê±´ì— ë§ëŠ” ì‹¤í—˜ í”„ë¡œí† ì½œ 3ê°œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.
        ê° í”„ë¡œí† ì½œì— ëŒ€í•´:
        1. ì œëª©
        2. ê°„ë‹¨í•œ ì„¤ëª…
        3. ì£¼ìš” ë‹¨ê³„ (5-7ê°œ)
        4. í•„ìš”í•œ ì¬ë£Œ
        5. ì˜ˆìƒ ì†Œìš” ì‹œê°„
        6. ë‚œì´ë„ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰)
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        try:
            ai_response = self.api.get_ai_response(protocol_prompt, response_format="json")
            if ai_response and 'protocols' in ai_response:
                for i, protocol in enumerate(ai_response['protocols']):
                    results.append({
                        'id': f"protocol_ai_{i}",
                        'type': 'protocol',
                        'title': protocol.get('title', ''),
                        'description': protocol.get('description', ''),
                        'steps': protocol.get('steps', []),
                        'materials': protocol.get('materials', []),
                        'duration': protocol.get('duration', ''),
                        'difficulty': protocol.get('difficulty', ''),
                        'source': 'AI Generated',
                        'reproducibility_score': 0.85
                    })
        except Exception as e:
            st.warning(f"AI í”„ë¡œí† ì½œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    def _generate_ai_materials(self, query: str, filters: Dict) -> List[Dict]:
        """AI ê¸°ë°˜ ì¬ë£Œ ì •ë³´ ìƒì„± (í´ë°±)"""
        results = []
        
        material_prompt = f"""
        ê²€ìƒ‰ì–´: {query}
        ê³ ë¶„ì ì¢…ë¥˜: {', '.join(filters.get('polymer_types', []))}
        ê´€ì‹¬ ë¬¼ì„±: {', '.join(filters.get('properties', []))}
        
        ìœ„ ì¡°ê±´ì— ë§ëŠ” ì¬ë£Œ ì •ë³´ 3ê°œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
        ê° ì¬ë£Œì— ëŒ€í•´:
        1. ì¬ë£Œëª…
        2. í™”í•™ì‹/êµ¬ì¡°
        3. ì£¼ìš” ë¬¼ì„± (ìš”ì²­ëœ ë¬¼ì„± ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ í¬í•¨)
        4. ì‘ìš© ë¶„ì•¼
        5. ì°¸ê³  ë¬¸í—Œ
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        try:
            ai_response = self.api.get_ai_response(material_prompt, response_format="json")
            if ai_response and 'materials' in ai_response:
                for i, material in enumerate(ai_response['materials']):
                    results.append({
                        'id': f"material_ai_{i}",
                        'type': 'material',
                        'title': material.get('name', ''),
                        'formula': material.get('formula', ''),
                        'properties': material.get('properties', {}),
                        'applications': material.get('applications', []),
                        'references': material.get('references', []),
                        'source': 'AI Database'
                    })
        except Exception as e:
            st.warning(f"AI ì¬ë£Œ ì •ë³´ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    def _get_available_sources(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì†ŒìŠ¤ ëª©ë¡"""
        sources = [
            "OpenAlex",      # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥ (ë¬´ë£Œ)
            "Crossref",      # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥ (ë¬´ë£Œ)
            "Patents",       # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥ (ë¬´ë£Œ)
            "PubChem",       # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥ (ë¬´ë£Œ)
        ]
        
        if ARXIV_AVAILABLE:
            sources.append("arXiv")
        
        if self.github_client:
            sources.append("GitHub")
        
        if self.zenodo_token:
            sources.append("Zenodo")
        else:
            sources.append("Zenodo")  # í† í° ì—†ì´ë„ ì œí•œì  ì‚¬ìš© ê°€ëŠ¥
        
        if self.protocols_token:
            sources.append("protocols.io")
        else:
            sources.append("protocols.io")  # AI í´ë°± ì‚¬ìš©
        
        if self.mp_client:
            sources.append("Materials Project")
        else:
            sources.append("Materials Project")  # AI í´ë°± ì‚¬ìš©
        
        return sources
    
    def _get_default_sources(self) -> List[str]:
        """ê¸°ë³¸ ì„ íƒ ì†ŒìŠ¤"""
        defaults = ["OpenAlex", "Crossref", "PubChem"]
        
        if self.github_client:
            defaults.append("GitHub")
        
        return defaults
    
    # === ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ì´ì „ ì½”ë“œì™€ ë™ì¼ ===
    # (_render_search_interface, _render_search_results, _render_papers ë“±)
    # ì´ì „ ì½”ë“œì—ì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    
    def _render_search_interface(self):
        """ê²€ìƒ‰ ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
        with st.container():
            # ê²€ìƒ‰ ì „ëµ ì¶”ì²œ
            if st.checkbox("ğŸ¤– AI ê²€ìƒ‰ ì „ëµ ì¶”ì²œ", value=True):
                self._render_search_strategy()
            
            # ë©”ì¸ ê²€ìƒ‰ ë°”
            col1, col2 = st.columns([4, 1])
            
            with col1:
                search_query = st.text_area(
                    "ë¬´ì—‡ì„ ì°¾ê³  ê³„ì‹ ê°€ìš”?",
                    placeholder="ì˜ˆ: PLA 3D í”„ë¦°íŒ… ìµœì  ì¡°ê±´, PEDOT:PSS ì „ë„ë„ í–¥ìƒ ë°©ë²•, ìƒë¶„í•´ì„± ê³ ë¶„ì í•©ì„±...",
                    height=80,
                    key="search_query"
                )
                
                # ê²€ìƒ‰ ì œì•ˆ
                if search_query and len(search_query) > 3:
                    suggestions = self._get_search_suggestions(search_query)
                    if suggestions:
                        st.info(f"ğŸ’¡ ì¶”ì²œ í‚¤ì›Œë“œ: {', '.join(suggestions[:5])}")
            
            with col2:
                st.write("")  # ê³µë°±
                search_button = st.button(
                    "ğŸ” í†µí•© ê²€ìƒ‰",
                    type="primary",
                    use_container_width=True,
                    disabled=not search_query
                )
            
            # ê³ ê¸‰ ê²€ìƒ‰ ì˜µì…˜
            with st.expander("ğŸ”§ ê³ ê¸‰ ê²€ìƒ‰ ì˜µì…˜", expanded=False):
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    resource_types = st.multiselect(
                        "ë¦¬ì†ŒìŠ¤ íƒ€ì…",
                        ["ğŸ“„ ë…¼ë¬¸", "ğŸ“‹ íŠ¹í—ˆ", "ğŸ”¬ í”„ë¡œí† ì½œ", 
                         "ğŸ“Š ì‹¤í—˜ë°ì´í„°", "ğŸ’» ì½”ë“œ", "ğŸ§ª ì¬ë£Œì •ë³´"],
                        default=["ğŸ“„ ë…¼ë¬¸", "ğŸ”¬ í”„ë¡œí† ì½œ", "ğŸ“Š ì‹¤í—˜ë°ì´í„°"],
                        key="resource_types"
                    )
                    
                    sources = st.multiselect(
                        "ë°ì´í„° ì†ŒìŠ¤",
                        self._get_available_sources(),
                        default=self._get_default_sources(),
                        key="sources"
                    )
                
                with col2:
                    properties = st.multiselect(
                        "ê´€ì‹¬ ë¬¼ì„±",
                        ["ì¸ì¥ê°•ë„", "ì‹ ìœ¨", "íˆ¬ëª…ë„", "ë‚´ì—´ì„±", 
                         "ë‚´í™”í•™ì„±", "ê°€ê³µì„±", "ê²°ì •í™”ë„", "ë¶„ìëŸ‰",
                         "ì „ê¸°ì „ë„ë„", "ì—´ì „ë„ë„", "êµ´ì ˆë¥ ", "ë°€ë„"],
                        key="properties"
                    )
                    
                    polymer_types = st.multiselect(
                        "ê³ ë¶„ì ì¢…ë¥˜",
                        ["PLA", "PCL", "PHA", "PBS", "PBAT", "PHB",
                         "PEDOT:PSS", "P3HT", "PANI", "PPy",
                         "PET", "PE", "PP", "PS", "PVC", "PA"],
                        key="polymer_types"
                    )
                
                with col3:
                    date_range = st.date_input(
                        "ê¸°ê°„",
                        value=(datetime.now() - timedelta(days=365*3), datetime.now()),
                        key="date_range"
                    )
                    
                    min_citations = st.number_input(
                        "ìµœì†Œ ì¸ìš©ìˆ˜",
                        min_value=0,
                        value=0,
                        key="min_citations"
                    )
                    
                    languages = st.multiselect(
                        "ì–¸ì–´",
                        ["English", "í•œêµ­ì–´", "ä¸­æ–‡", "æ—¥æœ¬èª"],
                        default=["English", "í•œêµ­ì–´"],
                        key="languages"
                    )
                
                with col4:
                    verified_only = st.checkbox("ê²€ì¦ëœ ìë£Œë§Œ", key="verified_only")
                    has_raw_data = st.checkbox("ì›ë³¸ ë°ì´í„° í¬í•¨", key="has_raw_data")
                    open_access = st.checkbox("ì˜¤í”ˆ ì•¡ì„¸ìŠ¤ë§Œ", key="open_access")
                    
                    sort_by = st.selectbox(
                        "ì •ë ¬ ê¸°ì¤€",
                        ["ê´€ë ¨ë„", "ìµœì‹ ìˆœ", "ì¸ìš©ìˆœ", "ì¬í˜„ì„±"],
                        key="sort_by"
                    )
            
            # ê²€ìƒ‰ ì‹¤í–‰
            if search_button:
                self._execute_search(search_query)
    
    def _render_search_strategy(self):
        """AI ê²€ìƒ‰ ì „ëµ ì¶”ì²œ"""
        with st.container():
            strategy_query = st.text_input(
                "ì—°êµ¬ ëª©í‘œë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                placeholder="ì˜ˆ: 3D í”„ë¦°íŒ…ìš© ìƒë¶„í•´ì„± í•„ë¼ë©˜íŠ¸ ê°œë°œ",
                key="strategy_query"
            )
            
            if strategy_query:
                with st.spinner("AIê°€ ìµœì ì˜ ê²€ìƒ‰ ì „ëµì„ ë¶„ì„ ì¤‘..."):
                    strategy = self._get_ai_search_strategy(strategy_query)
                    
                if strategy:
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.write("**ğŸ¯ ì¶”ì²œ í‚¤ì›Œë“œ**")
                        for kw in strategy.get('keywords', [])[:5]:
                            if st.button(f"â• {kw}", key=f"add_kw_{kw}"):
                                current = st.session_state.get('search_query', '')
                                st.session_state.search_query = f"{current} {kw}".strip()
                                st.rerun()
                    
                    with col2:
                        st.write("**ğŸ“š ì¶”ì²œ ë°ì´í„°ì†ŒìŠ¤**")
                        for src in strategy.get('sources', [])[:5]:
                            st.write(f"â€¢ {src}")
                    
                    with col3:
                        st.write("**ğŸ’¡ ê²€ìƒ‰ íŒ**")
                        for tip in strategy.get('tips', [])[:3]:
                            st.write(f"â€¢ {tip}")
                    
                    # AI ì„¤ëª… ìƒì„¸ë„ ì œì–´
                    self._render_ai_explanation(strategy, "search_strategy")
    
    def _execute_search(self, query: str):
        """í†µí•© ê²€ìƒ‰ ì‹¤í–‰"""
        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ìˆ˜ì§‘
        filters = {
            'resource_types': st.session_state.get('resource_types', []),
            'sources': st.session_state.get('sources', []),
            'properties': st.session_state.get('properties', []),
            'polymer_types': st.session_state.get('polymer_types', []),
            'date_range': st.session_state.get('date_range'),
            'min_citations': st.session_state.get('min_citations', 0),
            'languages': st.session_state.get('languages', []),
            'verified_only': st.session_state.get('verified_only', False),
            'has_raw_data': st.session_state.get('has_raw_data', False),
            'open_access': st.session_state.get('open_access', False),
            'sort_by': st.session_state.get('sort_by', 'ê´€ë ¨ë„')
        }
        
        with st.spinner("ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ìë£Œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰
            results = self._parallel_search(query, filters, progress_bar, status_text)
            
            # AI í†µí•© ë¶„ì„
            status_text.text("ğŸ¤– AIê°€ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            integrated_results = self._integrate_search_results(results, query)
            progress_bar.progress(100)
            
            # ê²°ê³¼ ì €ì¥
            st.session_state.search_results = integrated_results
            
            # ê²€ìƒ‰ ê¸°ë¡ ì €ì¥
            self._save_search_history(query, filters, integrated_results)
            
            status_text.text("âœ… ê²€ìƒ‰ ì™„ë£Œ!")
            time.sleep(1)
            st.rerun()
    
    def _search_arxiv(self, query: str, filters: Dict) -> List[Dict]:
        """arXiv ê²€ìƒ‰"""
        results = []
        
        try:
            # ê²€ìƒ‰ì–´ êµ¬ì„±
            search_query = self._build_arxiv_query(query, filters)
            
            # ê²€ìƒ‰ ì‹¤í–‰
            search = arxiv.Search(
                query=search_query,
                max_results=20,
                sort_by=arxiv.SortCriterion.Relevance
            )
            
            for paper in search.results():
                # ë‚ ì§œ í•„í„°ë§
                if filters['date_range']:
                    if paper.published.date() < filters['date_range'][0] or \
                       paper.published.date() > filters['date_range'][1]:
                        continue
                
                results.append({
                    'id': paper.entry_id.split('/')[-1],
                    'type': 'paper',
                    'title': paper.title,
                    'authors': [author.name for author in paper.authors],
                    'year': paper.published.year,
                    'abstract': paper.summary,
                    'url': paper.entry_id,
                    'pdf_url': paper.pdf_url,
                    'source': 'arXiv',
                    'categories': paper.categories,
                    'updated': paper.updated.strftime('%Y-%m-%d')
                })
                
        except Exception as e:
            st.error(f"arXiv ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    def _search_github(self, query: str, filters: Dict) -> List[Dict]:
        """GitHub ê²€ìƒ‰"""
        results = []
        
        if not self.github_client:
            return results
        
        try:
            # ê²€ìƒ‰ì–´ êµ¬ì„±
            search_query = f"{query} polymer"
            if filters.get('polymer_types'):
                search_query += f" {' '.join(filters['polymer_types'])}"
            
            # ì €ì¥ì†Œ ê²€ìƒ‰
            repos = self.github_client.search_repositories(
                query=search_query,
                sort='stars',
                order='desc'
            )
            
            for repo in repos[:10]:
                # ê´€ë ¨ íŒŒì¼ ì°¾ê¸°
                data_files = []
                code_files = []
                
                try:
                    contents = repo.get_contents("")
                    while contents:
                        file_content = contents.pop(0)
                        if file_content.type == "dir":
                            # íŠ¹ì • ë””ë ‰í† ë¦¬ë§Œ íƒìƒ‰ (ì„±ëŠ¥ ìµœì í™”)
                            if file_content.name in ['data', 'results', 'experiments']:
                                contents.extend(repo.get_contents(file_content.path))
                        else:
                            # ë°ì´í„° íŒŒì¼
                            if any(file_content.name.endswith(ext) for ext in ['.csv', '.xlsx', '.json', '.hdf5']):
                                data_files.append({
                                    'name': file_content.name,
                                    'path': file_content.path,
                                    'size': file_content.size,
                                    'url': file_content.download_url
                                })
                            # ì½”ë“œ íŒŒì¼
                            elif any(file_content.name.endswith(ext) for ext in ['.py', '.ipynb', '.m', '.R']):
                                code_files.append({
                                    'name': file_content.name,
                                    'path': file_content.path,
                                    'url': file_content.html_url
                                })
                except:
                    pass
                
                # ë°ì´í„°ì…‹ìœ¼ë¡œ ë¶„ë¥˜
                if data_files:
                    results.append({
                        'id': f"github_data_{repo.id}",
                        'type': 'dataset',
                        'title': f"{repo.name} - Dataset",
                        'description': repo.description or '',
                        'source': 'GitHub',
                        'url': repo.html_url,
                        'size': sum(f['size'] for f in data_files),
                        'formats': list(set(f['name'].split('.')[-1] for f in data_files)),
                        'files': data_files[:5],  # ìµœëŒ€ 5ê°œ
                        'stars': repo.stargazers_count,
                        'updated': repo.updated_at.strftime('%Y-%m-%d')
                    })
                
                # ì½”ë“œë¡œ ë¶„ë¥˜
                if code_files:
                    results.append({
                        'id': f"github_code_{repo.id}",
                        'type': 'code',
                        'title': repo.name,
                        'description': repo.description or '',
                        'source': 'GitHub',
                        'url': repo.html_url,
                        'language': repo.language,
                        'files': code_files[:5],  # ìµœëŒ€ 5ê°œ
                        'stars': repo.stargazers_count,
                        'topics': repo.get_topics(),
                        'updated': repo.updated_at.strftime('%Y-%m-%d')
                    })
                    
        except Exception as e:
            st.error(f"GitHub ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    def _integrate_search_results(self, results: Dict, query: str) -> Dict:
        """ê²€ìƒ‰ ê²°ê³¼ í†µí•© ë° AI ë¶„ì„"""
        # AI í†µí•© ë¶„ì„
        analysis_prompt = f"""
        ê²€ìƒ‰ì–´: {query}
        
        ê²€ìƒ‰ ê²°ê³¼:
        - ë…¼ë¬¸: {len(results['papers'])}ê°œ
        - íŠ¹í—ˆ: {len(results.get('patents', []))}ê°œ
        - í”„ë¡œí† ì½œ: {len(results['protocols'])}ê°œ  
        - ë°ì´í„°ì…‹: {len(results['datasets'])}ê°œ
        - ì½”ë“œ: {len(results['code'])}ê°œ
        - ì¬ë£Œì •ë³´: {len(results['materials'])}ê°œ
        
        ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1. í•µì‹¬ ë°œê²¬ì‚¬í•­ (2-3ë¬¸ì¥)
        2. ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ìë£Œ Top 3
        3. ì¶”ì²œ ì‹¤í—˜ í”„ë¡œí† ì½œ
        4. ì£¼ì˜ì‚¬í•­ì´ë‚˜ ê³ ë ¤ì‚¬í•­
        5. ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œ ì œì•ˆ
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        try:
            ai_analysis = self.api.get_ai_response(analysis_prompt, response_format="json")
            results['ai_analysis'] = ai_analysis
        except Exception as e:
            results['ai_analysis'] = None
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        results = self._deduplicate_results(results)
        results = self._sort_results(results)
        
        # íŠ¹í—ˆ ì¹´í…Œê³ ë¦¬ ì¶”ê°€ (ì´ì „ ì½”ë“œì—ì„œ ëˆ„ë½ë¨)
        if 'patents' not in results:
            results['patents'] = []
        
        return results
    
    def _render_search_results(self):
        """ê²€ìƒ‰ ê²°ê³¼ ë Œë”ë§"""
        results = st.session_state.search_results
        
        # ê²°ê³¼ ìš”ì•½
        col1, col2, col3, col4, col5, col6, col7 = st.columns(7)
        
        with col1:
            st.metric("ì´ ê²°ê³¼", results['total_count'])
        with col2:
            st.metric("ë…¼ë¬¸", len(results['papers']))
        with col3:
            st.metric("íŠ¹í—ˆ", len(results.get('patents', [])))
        with col4:
            st.metric("í”„ë¡œí† ì½œ", len(results['protocols']))
        with col5:
            st.metric("ë°ì´í„°ì…‹", len(results['datasets']))
        with col6:
            st.metric("ì½”ë“œ", len(results['code']))
        with col7:
            st.metric("ì¬ë£Œì •ë³´", len(results['materials']))
        
        # AI ë¶„ì„ ê²°ê³¼
        if results.get('ai_analysis'):
            with st.container():
                st.subheader("ğŸ¤– AI í†µí•© ë¶„ì„")
                
                analysis = results['ai_analysis']
                
                # í•µì‹¬ ë°œê²¬ì‚¬í•­
                if analysis.get('key_findings'):
                    st.info(f"**í•µì‹¬ ë°œê²¬:** {analysis['key_findings']}")
                
                # ì¶”ì²œ ìë£Œ
                if analysis.get('top_resources'):
                    with st.expander("ğŸ“Œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ìë£Œ", expanded=True):
                        for i, resource in enumerate(analysis['top_resources'][:3]):
                            st.write(f"{i+1}. **{resource.get('title', '')}**")
                            st.write(f"   - ìœ í˜•: {resource.get('type', '')}")
                            st.write(f"   - ì´ìœ : {resource.get('reason', '')}")
                
                # AI ì„¤ëª… ìƒì„¸ë„ ì œì–´
                self._render_ai_explanation(analysis, "search_analysis")
        
        # íƒ­ë³„ ê²°ê³¼ í‘œì‹œ
        tabs = st.tabs(["ğŸ“„ ë…¼ë¬¸", "ğŸ“‹ íŠ¹í—ˆ", "ğŸ”¬ í”„ë¡œí† ì½œ", "ğŸ“Š ë°ì´í„°ì…‹", "ğŸ’» ì½”ë“œ", "ğŸ§ª ì¬ë£Œì •ë³´", "ğŸ“Š í†µí•© ë·°"])
        
        with tabs[0]:
            self._render_papers(results['papers'])
        
        with tabs[1]:
            self._render_patents(results.get('patents', []))
        
        with tabs[2]:
            self._render_protocols(results['protocols'])
        
        with tabs[3]:
            self._render_datasets(results['datasets'])
        
        with tabs[4]:
            self._render_code(results['code'])
        
        with tabs[5]:
            self._render_materials(results['materials'])
        
        with tabs[6]:
            self._render_integrated_view(results)
    
    def _render_patents(self, patents: List[Dict]):
        """íŠ¹í—ˆ ê²°ê³¼ ë Œë”ë§"""
        if not patents:
            self.ui.render_empty_state("ê²€ìƒ‰ëœ íŠ¹í—ˆê°€ ì—†ìŠµë‹ˆë‹¤", "ğŸ“‹")
            return
        
        for patent in patents:
            with st.container():
                col1, col2 = st.columns([4, 1])
                
                with col1:
                    st.markdown(f"### [{patent['title']}]({patent.get('url', '#')})")
                    
                    # ë°œëª…ì
                    if patent.get('inventors'):
                        st.write(f"**ë°œëª…ì:** {', '.join(patent['inventors'])}")
                    
                    # ì¶œì›ì¼
                    if patent.get('date'):
                        st.write(f"**ì¶œì›ì¼:** {patent['date']}")
                    
                    # ì´ˆë¡
                    if patent.get('abstract'):
                        with st.expander("ì´ˆë¡ ë³´ê¸°"):
                            st.write(patent['abstract'])
                
                with col2:
                    st.write(f"**íŠ¹í—ˆë²ˆí˜¸:** {patent.get('id', 'N/A')}")
                    
                    # ì•¡ì…˜ ë²„íŠ¼
                    if st.button("ğŸ“„ ìƒì„¸ë³´ê¸°", key=f"patent_view_{patent['id']}"):
                        st.info(f"íŠ¹í—ˆ ìƒì„¸ í˜ì´ì§€ë¡œ ì´ë™: {patent.get('url', '')}")
                    
                    if st.button("ğŸ’¾ ì €ì¥", key=f"save_patent_{patent['id']}"):
                        self._save_resource(patent, 'patent')
                
                st.divider()
    
    def _render_papers(self, papers: List[Dict]):
        """ë…¼ë¬¸ ê²°ê³¼ ë Œë”ë§"""
        if not papers:
            self.ui.render_empty_state("ê²€ìƒ‰ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤", "ğŸ“š")
            return
        
        # í•„í„° ë° ì •ë ¬
        col1, col2, col3 = st.columns([2, 2, 1])
        with col1:
            journal_filter = st.multiselect(
                "ì €ë„ í•„í„°",
                list(set(p.get('journal', 'Unknown') for p in papers if p.get('journal'))),
                key="journal_filter"
            )
        with col2:
            year_filter = st.slider(
                "ì¶œíŒë…„ë„",
                min_value=min(int(p.get('year', 2020)) for p in papers if p.get('year')),
                max_value=max(int(p.get('year', 2024)) for p in papers if p.get('year')),
                value=(2020, 2024),
                key="year_filter"
            )
        with col3:
            sort_papers = st.selectbox(
                "ì •ë ¬",
                ["ê´€ë ¨ë„", "ìµœì‹ ìˆœ", "ì¸ìš©ìˆœ"],
                key="sort_papers"
            )
        
        # ë…¼ë¬¸ ì¹´ë“œ í‘œì‹œ
        for paper in papers:
            with st.container():
                col1, col2 = st.columns([4, 1])
                
                with col1:
                    st.markdown(f"### [{paper['title']}]({paper.get('url', '#')})")
                    st.write(f"**ì €ì:** {', '.join(paper['authors'][:3])}{'...' if len(paper['authors']) > 3 else ''}")
                    st.write(f"**ì¶œì²˜:** {paper['source']} | {paper.get('journal', '')} ({paper.get('year', 'N/A')})")
                    
                    # DOI
                    if paper.get('doi'):
                        st.write(f"**DOI:** {paper['doi']}")
                    
                    # ì´ˆë¡
                    with st.expander("ì´ˆë¡ ë³´ê¸°"):
                        st.write(paper.get('abstract', 'ì´ˆë¡ ì •ë³´ ì—†ìŒ'))
                    
                    # í‚¤ì›Œë“œ/ê°œë…
                    if paper.get('concepts'):
                        st.write(f"**ê°œë…:** {', '.join(paper['concepts'][:5])}")
                    elif paper.get('keywords'):
                        st.write(f"**í‚¤ì›Œë“œ:** {', '.join(paper['keywords'][:5])}")
                
                with col2:
                    st.metric("ì¸ìš©ìˆ˜", paper.get('citations', 0))
                    
                    # ì˜¤í”ˆ ì•¡ì„¸ìŠ¤ í‘œì‹œ
                    if paper.get('open_access'):
                        st.success("ğŸ”“ ì˜¤í”ˆ ì•¡ì„¸ìŠ¤")
                    
                    # ì•¡ì…˜ ë²„íŠ¼
                    if paper.get('pdf_url'):
                        if st.button("ğŸ“„ PDF", key=f"pdf_{paper['id']}"):
                            self._download_pdf(paper['pdf_url'])
                    
                    if st.button("ğŸ”¬ í”„ë¡œí† ì½œ ì¶”ì¶œ", key=f"extract_{paper['id']}"):
                        self._extract_protocol_from_paper(paper)
                    
                    if st.button("ğŸ’¾ ì €ì¥", key=f"save_paper_{paper['id']}"):
                        self._save_resource(paper, 'paper')
                
                st.divider()
    
    def _render_protocols(self, protocols: List[Dict]):
        """í”„ë¡œí† ì½œ ê²°ê³¼ ë Œë”ë§"""
        if not protocols:
            self.ui.render_empty_state("ê²€ìƒ‰ëœ í”„ë¡œí† ì½œì´ ì—†ìŠµë‹ˆë‹¤", "ğŸ”¬")
            return
        
        for protocol in protocols:
            with st.container():
                col1, col2 = st.columns([4, 1])
                
                with col1:
                    st.markdown(f"### {protocol['title']}")
                    st.write(protocol.get('description', ''))
                    
                    # í”„ë¡œí† ì½œ ë‹¨ê³„
                    if protocol.get('steps'):
                        with st.expander("ì‹¤í—˜ ë‹¨ê³„ ë³´ê¸°"):
                            for i, step in enumerate(protocol['steps']):
                                st.write(f"{i+1}. {step}")
                    
                    # ì¬ë£Œ
                    if protocol.get('materials'):
                        with st.expander("í•„ìš”í•œ ì¬ë£Œ"):
                            for material in protocol['materials']:
                                st.write(f"â€¢ {material}")
                    
                    # ë©”íƒ€ë°ì´í„°
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.write(f"**ë‚œì´ë„:** {protocol.get('difficulty', 'N/A')}")
                    with col_b:
                        st.write(f"**ì†Œìš”ì‹œê°„:** {protocol.get('duration', 'N/A')}")
                    with col_c:
                        st.write(f"**ì¶œì²˜:** {protocol.get('source', 'N/A')}")
                    
                    # ì €ì ì •ë³´
                    if protocol.get('authors'):
                        st.write(f"**ì €ì:** {', '.join(protocol['authors'])}")
                
                with col2:
                    # ì¬í˜„ì„± ì ìˆ˜
                    score = protocol.get('reproducibility_score', 0)
                    st.metric("ì¬í˜„ì„±", f"{score:.0%}")
                    
                    # ì•¡ì…˜ ë²„íŠ¼
                    if protocol.get('url'):
                        if st.button("ğŸ”— ì›ë³¸ë³´ê¸°", key=f"view_protocol_{protocol['id']}"):
                            st.info(f"ì›ë³¸ ë§í¬: {protocol['url']}")
                    
                    if st.button("ğŸ“‹ ë³µì‚¬", key=f"copy_protocol_{protocol['id']}"):
                        self._copy_protocol(protocol)
                    
                    if st.button("ğŸ§ª ì‹¤í—˜ ì„¤ê³„ë¡œ", key=f"design_{protocol['id']}"):
                        st.session_state.selected_protocol = protocol
                        st.switch_page("pages/3_ğŸ§ª_Experiment_Design.py")
                    
                    if st.button("ğŸ’¾ ì €ì¥", key=f"save_protocol_{protocol['id']}"):
                        self._save_resource(protocol, 'protocol')
                
                st.divider()
    
    def _render_datasets(self, datasets: List[Dict]):
        """ë°ì´í„°ì…‹ ê²°ê³¼ ë Œë”ë§"""
        if not datasets:
            self.ui.render_empty_state("ê²€ìƒ‰ëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤", "ğŸ“Š")
            return
        
        for dataset in datasets:
            with st.container():
                col1, col2 = st.columns([4, 1])
                
                with col1:
                    st.markdown(f"### [{dataset['title']}]({dataset.get('url', '#')})")
                    st.write(dataset.get('description', 'ì„¤ëª… ì—†ìŒ'))
                    
                    # ì œì‘ì
                    if dataset.get('creators'):
                        st.write(f"**ì œì‘ì:** {', '.join(dataset['creators'][:3])}")
                    
                    # DOI
                    if dataset.get('doi'):
                        st.write(f"**DOI:** {dataset['doi']}")
                    
                    # íŒŒì¼ ì •ë³´
                    if dataset.get('files'):
                        with st.expander("í¬í•¨ëœ íŒŒì¼"):
                            for file in dataset['files'][:5]:
                                st.write(f"â€¢ {file['name']} ({file.get('size', 0):,} bytes)")
                    
                    # ë©”íƒ€ë°ì´í„°
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.write(f"**í¬ë§·:** {', '.join(dataset.get('formats', []))}")
                    with col_b:
                        st.write(f"**í¬ê¸°:** {dataset.get('size', 0):,} bytes")
                    with col_c:
                        st.write(f"**ì—…ë°ì´íŠ¸:** {dataset.get('updated', dataset.get('published', 'N/A'))}")
                    
                    # í‚¤ì›Œë“œ
                    if dataset.get('keywords'):
                        st.write(f"**í‚¤ì›Œë“œ:** {', '.join(dataset['keywords'][:5])}")
                    
                    # ë¼ì´ì„ ìŠ¤
                    if dataset.get('license'):
                        st.write(f"**ë¼ì´ì„ ìŠ¤:** {dataset['license']}")
                
                with col2:
                    if dataset['source'] == 'GitHub':
                        st.metric("â­", dataset.get('stars', 0))
                    
                    # ì•¡ì…˜ ë²„íŠ¼
                    if st.button("ğŸ’¾ ë‹¤ìš´ë¡œë“œ", key=f"download_{dataset['id']}"):
                        self._download_dataset(dataset)
                    
                    if st.button("ğŸ“ˆ ë¶„ì„", key=f"analyze_{dataset['id']}"):
                        st.session_state.selected_dataset = dataset
                        st.switch_page("pages/4_ğŸ“ˆ_Data_Analysis.py")
                    
                    if st.button("ğŸ’¾ ì €ì¥", key=f"save_dataset_{dataset['id']}"):
                        self._save_resource(dataset, 'dataset')
                
                st.divider()
    
    def _render_code(self, code_items: List[Dict]):
        """ì½”ë“œ ê²°ê³¼ ë Œë”ë§"""
        if not code_items:
            self.ui.render_empty_state("ê²€ìƒ‰ëœ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤", "ğŸ’»")
            return
        
        for code in code_items:
            with st.container():
                col1, col2 = st.columns([4, 1])
                
                with col1:
                    st.markdown(f"### [{code['title']}]({code.get('url', '#')})")
                    st.write(code.get('description', 'ì„¤ëª… ì—†ìŒ'))
                    
                    # ì €ì¥ì†Œ ì •ë³´ (GitHub ì½”ë“œì˜ ê²½ìš°)
                    if code.get('repository'):
                        st.write(f"**ì €ì¥ì†Œ:** {code['repository']}")
                    
                    # íŒŒì¼ ê²½ë¡œ
                    if code.get('path'):
                        st.write(f"**ê²½ë¡œ:** {code['path']}")
                    
                    # íŒŒì¼ ëª©ë¡
                    if code.get('files'):
                        with st.expander("ì½”ë“œ íŒŒì¼"):
                            for file in code['files'][:5]:
                                st.write(f"â€¢ [{file['name']}]({file.get('url', '#')})")
                    
                    # ë©”íƒ€ë°ì´í„°
                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.write(f"**ì–¸ì–´:** {code.get('language', 'N/A')}")
                    with col_b:
                        st.write(f"**í† í”½:** {', '.join(code.get('topics', [])[:3])}")
                
                with col2:
                    if code['source'] == 'GitHub':
                        st.metric("â­", code.get('stars', 0))
                    
                    # ì•¡ì…˜ ë²„íŠ¼
                    if st.button("ğŸ‘ï¸ ë³´ê¸°", key=f"view_code_{code['id']}"):
                        self._view_code(code)
                    
                    if st.button("ğŸ”„ í´ë¡ ", key=f"clone_{code['id']}"):
                        if code.get('url'):
                            st.code(f"git clone {code['url']}.git")
                    
                    if st.button("ğŸ’¾ ì €ì¥", key=f"save_code_{code['id']}"):
                        self._save_resource(code, 'code')
                
                st.divider()
    
    def _render_materials(self, materials: List[Dict]):
        """ì¬ë£Œì •ë³´ ê²°ê³¼ ë Œë”ë§"""
        if not materials:
            self.ui.render_empty_state("ê²€ìƒ‰ëœ ì¬ë£Œì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤", "ğŸ§ª")
            return
        
        for material in materials:
            with st.container():
                st.markdown(f"### {material['title']}")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write(f"**í™”í•™ì‹:** {material.get('formula', 'N/A')}")
                    
                    # ê³µê°„êµ° (Materials Project)
                    if material.get('spacegroup'):
                        st.write(f"**ê³µê°„êµ°:** {material['spacegroup']}")
                    
                    # ë¬¼ì„± ì •ë³´
                    if material.get('properties'):
                        st.write("**ì£¼ìš” ë¬¼ì„±:**")
                        for prop, value in material['properties'].items():
                            st.write(f"â€¢ {prop}: {value}")
                
                with col2:
                    # ì‘ìš© ë¶„ì•¼
                    if material.get('applications'):
                        st.write("**ì‘ìš© ë¶„ì•¼:**")
                        for app in material['applications']:
                            st.write(f"â€¢ {app}")
                    
                    # ì°¸ê³ ë¬¸í—Œ
                    if material.get('references'):
                        with st.expander("ì°¸ê³ ë¬¸í—Œ"):
                            for ref in material['references']:
                                st.write(f"â€¢ {ref}")
                    
                    # URL
                    if material.get('url'):
                        st.write(f"**ë°ì´í„°ë² ì´ìŠ¤:** [{material['source']}]({material['url']})")
                
                # ì•¡ì…˜ ë²„íŠ¼
                col1, col2, col3 = st.columns(3)
                with col1:
                    if st.button("ğŸ§ª ì‹¤í—˜ ì„¤ê³„", key=f"material_design_{material['id']}"):
                        st.session_state.selected_material = material
                        st.switch_page("pages/3_ğŸ§ª_Experiment_Design.py")
                with col2:
                    if st.button("ğŸ“Š ë¬¼ì„± ë¹„êµ", key=f"compare_{material['id']}"):
                        self._compare_materials(material)
                with col3:
                    if st.button("ğŸ’¾ ì €ì¥", key=f"save_material_{material['id']}"):
                        self._save_resource(material, 'material')
                
                st.divider()
    
    def _render_integrated_view(self, results: Dict):
        """í†µí•© ë·° ë Œë”ë§"""
        st.subheader("ğŸ”— ì—°ê²°ëœ ë¦¬ì†ŒìŠ¤ ë„¤íŠ¸ì›Œí¬")
        
        # ë¦¬ì†ŒìŠ¤ ê°„ ì—°ê²° ì‹œê°í™”
        fig = self._create_resource_network(results)
        st.plotly_chart(fig, use_container_width=True)
        
        # í†µí•© íƒ€ì„ë¼ì¸
        st.subheader("ğŸ“… ì—°êµ¬ íƒ€ì„ë¼ì¸")
        timeline_fig = self._create_research_timeline(results)
        st.plotly_chart(timeline_fig, use_container_width=True)
        
        # ì—°êµ¬ ê°­ ë¶„ì„
        st.subheader("ğŸ” ì—°êµ¬ ê°­ ë¶„ì„")
        gaps = self._analyze_research_gaps(results)
        
        if gaps:
            for gap in gaps:
                with st.expander(gap['title']):
                    st.write(gap['description'])
                    st.write(f"**ì¶”ì²œ ì ‘ê·¼ë²•:** {gap['recommendation']}")
    
    def _render_ai_explanation(self, data: Dict, context: str):
        """AI ì„¤ëª… ìƒì„¸ë„ ì œì–´ ë Œë”ë§"""
        # í˜„ì¬ ìƒì„¸ë„ ìƒíƒœ
        show_details = st.session_state.get(f'show_ai_details_{context}', False)
        
        col1, col2 = st.columns([4, 1])
        
        with col2:
            if st.button(
                "ğŸ” ìƒì„¸ ì„¤ëª… " + ("ìˆ¨ê¸°ê¸°" if show_details else "ë³´ê¸°"),
                key=f"toggle_details_{context}"
            ):
                st.session_state[f'show_ai_details_{context}'] = not show_details
                st.rerun()
        
        if show_details and data:
            with st.container():
                tabs = st.tabs(["ì¶”ë¡  ê³¼ì •", "ëŒ€ì•ˆ", "ë°°ê²½", "ì‹ ë¢°ë„"])
                
                with tabs[0]:
                    st.write("**AI ì¶”ë¡  ê³¼ì •:**")
                    if data.get('reasoning'):
                        st.write(data['reasoning'])
                    else:
                        st.write("ì´ ë¶„ì„ì€ ë‹¤ìŒ ë‹¨ê³„ë¡œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤:")
                        st.write("1. ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘ ë° ë¶„ë¥˜")
                        st.write("2. ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°")
                        st.write("3. êµì°¨ ì°¸ì¡° ë° ê²€ì¦")
                        st.write("4. í†µí•© ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ")
                
                with tabs[1]:
                    st.write("**ê²€í† í•œ ëŒ€ì•ˆë“¤:**")
                    if data.get('alternatives'):
                        for alt in data['alternatives']:
                            st.write(f"â€¢ {alt}")
                    else:
                        st.write("â€¢ ë‹¤ë¥¸ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¡°í•©")
                        st.write("â€¢ ì¶”ê°€ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰")
                        st.write("â€¢ ì‹œê°„ ë²”ìœ„ í™•ëŒ€")
                
                with tabs[2]:
                    st.write("**ì´ë¡ ì  ë°°ê²½:**")
                    if data.get('background'):
                        st.write(data['background'])
                    else:
                        st.write("ì´ ë¶„ì„ì€ ì •ë³´ ê²€ìƒ‰ ì´ë¡ ê³¼ ê³ ë¶„ì ê³¼í•™ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.")
                
                with tabs[3]:
                    confidence = data.get('confidence', 0.85)
                    st.write(f"**ë¶„ì„ ì‹ ë¢°ë„:** {confidence:.0%}")
                    st.progress(confidence)
                    if data.get('limitations'):
                        st.write("**í•œê³„ì :**")
                        for limit in data['limitations']:
                            st.write(f"â€¢ {limit}")
    
    def _render_recent_searches(self):
        """ìµœê·¼ ê²€ìƒ‰ ë Œë”ë§"""
        st.subheader("ğŸ•’ ìµœê·¼ ê²€ìƒ‰")
        
        # DBì—ì„œ ìµœê·¼ ê²€ìƒ‰ ê°€ì ¸ì˜¤ê¸°
        try:
            recent = self.sheets.read('search_history', 
                                     filters={'user_id': self.current_user['id']},
                                     order_by='timestamp',
                                     limit=5)
            
            if recent:
                for search in recent:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.write(f"**{search['query']}**")
                    with col2:
                        st.write(search['timestamp'][:10])
                    with col3:
                        if st.button("ì¬ê²€ìƒ‰", key=f"re_{search['query']}"):
                            st.session_state.search_query = search['query']
                            st.rerun()
            else:
                st.info("ìµœê·¼ ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
                
        except:
            # ë”ë¯¸ ë°ì´í„°
            recent_searches = [
                {"query": "PLA 3D printing optimization", "date": "2024-01-15", "results": 42},
                {"query": "PEDOT:PSS conductivity enhancement", "date": "2024-01-14", "results": 28},
            ]
            
            for search in recent_searches:
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.write(f"**{search['query']}**")
                with col2:
                    st.write(search['date'])
                with col3:
                    if st.button("ì¬ê²€ìƒ‰", key=f"re_{search['query']}"):
                        st.session_state.search_query = search['query']
                        st.rerun()
    
    def _render_saved_resources(self):
        """ì €ì¥ëœ ìë£Œ ë Œë”ë§"""
        st.subheader("ğŸ’¾ ì €ì¥ëœ ìë£Œ")
        
        # DBì—ì„œ ì €ì¥ëœ ìë£Œ ê°€ì ¸ì˜¤ê¸°
        try:
            saved = self.sheets.read('saved_resources',
                                    filters={'user_id': self.current_user['id']},
                                    order_by='saved_at',
                                    limit=5)
            
            if saved:
                for item in saved:
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.write(f"**{item['title']}**")
                        st.caption(f"ìœ í˜•: {item['resource_type']}")
                    with col2:
                        st.write(item['saved_at'][:10])
                    with col3:
                        if st.button("ì—´ê¸°", key=f"open_{item['resource_id']}"):
                            # ì €ì¥ëœ ë°ì´í„° ë³µì›
                            resource_data = json.loads(item['data'])
                            st.info(f"ìë£Œ ì—´ê¸°: {resource_data.get('url', '')}")
            else:
                st.info("ì €ì¥ëœ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except:
            st.info("ì €ì¥ëœ ìë£Œë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # === ì¶”ê°€ í—¬í¼ ë©”ì„œë“œë“¤ ===
    
    def _get_search_suggestions(self, query: str) -> List[str]:
        """ê²€ìƒ‰ì–´ ì œì•ˆ"""
        # AI ê¸°ë°˜ ê²€ìƒ‰ì–´ ì œì•ˆ
        prompt = f"""
        ê²€ìƒ‰ì–´: {query}
        
        ê³ ë¶„ì ì—°êµ¬ ê´€ë ¨ ì¶”ê°€ ê²€ìƒ‰ í‚¤ì›Œë“œ 5ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.
        í‚¤ì›Œë“œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ì‘ë‹µí•˜ì„¸ìš”.
        """
        
        try:
            response = self.api.get_ai_response(prompt)
            if response:
                return [kw.strip() for kw in response.split(',')][:5]
        except:
            pass
        
        # í´ë°±: ê¸°ë³¸ ì œì•ˆ
        return ["optimization", "characterization", "synthesis", "properties", "applications"]
    
    def _get_ai_search_strategy(self, goal: str) -> Dict:
        """AI ê²€ìƒ‰ ì „ëµ ìƒì„±"""
        prompt = f"""
        ì—°êµ¬ ëª©í‘œ: {goal}
        
        ìµœì ì˜ ê²€ìƒ‰ ì „ëµì„ ì œì•ˆí•´ì£¼ì„¸ìš”:
        1. í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ
        2. ì¶”ì²œ ë°ì´í„° ì†ŒìŠ¤ 3ê°œ
        3. ê²€ìƒ‰ íŒ 3ê°œ
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
        {{
            "keywords": [...],
            "sources": [...],
            "tips": [...]
        }}
        """
        
        try:
            response = self.api.get_ai_response(prompt, response_format="json")
            return response
        except Exception as e:
            # í´ë°± ì „ëµ
            return {
                "keywords": ["polymer", "optimization", "characterization"],
                "sources": ["OpenAlex", "GitHub", "protocols.io"],
                "tips": ["êµ¬ì²´ì ì¸ ê³ ë¶„ìëª… ì‚¬ìš©", "ë¬¼ì„±ê³¼ í•¨ê»˜ ê²€ìƒ‰", "ìµœì‹  ë…¼ë¬¸ ìš°ì„ "]
            }
    
    def _build_arxiv_query(self, query: str, filters: Dict) -> str:
        """arXiv ê²€ìƒ‰ì–´ êµ¬ì„±"""
        parts = [query]
        
        # arXiv ì¹´í…Œê³ ë¦¬ ì¶”ê°€
        parts.append("cat:cond-mat OR cat:physics OR cat:cs")
        
        if filters.get('polymer_types'):
            parts.extend(filters['polymer_types'])
        
        return ' '.join(parts)
    
    def _extract_protocol_from_paper(self, paper: Dict):
        """ë…¼ë¬¸ì—ì„œ í”„ë¡œí† ì½œ ì¶”ì¶œ"""
        with st.spinner("í”„ë¡œí† ì½œì„ ì¶”ì¶œí•˜ëŠ” ì¤‘..."):
            # PDF ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹± ì‹œë®¬ë ˆì´ì…˜
            if paper.get('pdf_url'):
                st.info(f"PDF URL: {paper['pdf_url']}")
                
                # AI ê¸°ë°˜ í”„ë¡œí† ì½œ ìƒì„±
                prompt = f"""
                ë…¼ë¬¸ ì œëª©: {paper['title']}
                ì´ˆë¡: {paper.get('abstract', '')}
                
                ì´ ë…¼ë¬¸ì˜ ê°€ëŠ¥í•œ ì‹¤í—˜ í”„ë¡œí† ì½œì„ ì¶”ë¡ í•´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                ë‹¨ê³„ë³„ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
                """
                
                try:
                    protocol = self.api.get_ai_response(prompt)
                    if protocol:
                        st.success("í”„ë¡œí† ì½œì´ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        with st.expander("ì¶”ì¶œëœ í”„ë¡œí† ì½œ"):
                            st.write(protocol)
                except Exception as e:
                    st.error(f"í”„ë¡œí† ì½œ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            else:
                st.warning("PDF URLì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def _deduplicate_results(self, results: Dict) -> Dict:
        """ì¤‘ë³µ ê²°ê³¼ ì œê±°"""
        # ì œëª© ê¸°ë°˜ ì¤‘ë³µ ì œê±°
        for category in ['papers', 'patents', 'protocols', 'datasets', 'code', 'materials']:
            if category in results:
                seen_titles = set()
                unique_items = []
                
                for item in results[category]:
                    title = item.get('title', '').lower()
                    if title and title not in seen_titles:
                        seen_titles.add(title)
                        unique_items.append(item)
                
                results[category] = unique_items
        
        return results
    
    def _sort_results(self, results: Dict) -> Dict:
        """ê²°ê³¼ ì •ë ¬"""
        sort_by = st.session_state.get('sort_by', 'ê´€ë ¨ë„')
        
        for category in ['papers', 'patents', 'protocols', 'datasets', 'code', 'materials']:
            if category in results and results[category]:
                if sort_by == "ìµœì‹ ìˆœ":
                    results[category].sort(
                        key=lambda x: x.get('year', 0) or x.get('updated', '') or x.get('published', ''),
                        reverse=True
                    )
                elif sort_by == "ì¸ìš©ìˆœ" and category == 'papers':
                    results[category].sort(
                        key=lambda x: x.get('citations', 0),
                        reverse=True
                    )
        
        return results
    
    def _save_search_history(self, query: str, filters: Dict, results: Dict):
        """ê²€ìƒ‰ ê¸°ë¡ ì €ì¥"""
        try:
            history_data = {
                'user_id': self.current_user['id'],
                'query': query,
                'filters': json.dumps(filters),
                'result_count': results['total_count'],
                'timestamp': datetime.now().isoformat()
            }
            
            self.sheets.create('search_history', history_data)
        except Exception as e:
            st.warning(f"ê²€ìƒ‰ ê¸°ë¡ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def _save_resource(self, resource: Dict, resource_type: str):
        """ìë£Œ ì €ì¥"""
        try:
            save_data = {
                'user_id': self.current_user['id'],
                'resource_type': resource_type,
                'resource_id': resource['id'],
                'title': resource['title'],
                'data': json.dumps(resource),
                'saved_at': datetime.now().isoformat()
            }
            
            self.sheets.create('saved_resources', save_data)
            st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        except Exception as e:
            st.error(f"ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def _create_resource_network(self, results: Dict) -> go.Figure:
        """ë¦¬ì†ŒìŠ¤ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”"""
        # ê°„ë‹¨í•œ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±
        fig = go.Figure()
        
        # ë…¸ë“œ ì¶”ê°€
        categories = ['papers', 'patents', 'protocols', 'datasets', 'code', 'materials']
        colors = ['blue', 'green', 'red', 'purple', 'orange', 'brown']
        
        for i, category in enumerate(categories):
            count = len(results.get(category, []))
            if count > 0:
                fig.add_trace(go.Scatter(
                    x=[i * 2],
                    y=[0],
                    mode='markers+text',
                    marker=dict(size=30 + count * 5, color=colors[i]),
                    text=[f"{category}\n({count})"],
                    textposition="top center",
                    name=category
                ))
        
        fig.update_layout(
            title="ê²€ìƒ‰ ê²°ê³¼ ë¶„í¬",
            showlegend=False,
            xaxis=dict(showgrid=False, zeroline=False, visible=False),
            yaxis=dict(showgrid=False, zeroline=False, visible=False),
            height=300
        )
        
        return fig
    
    def _create_research_timeline(self, results: Dict) -> go.Figure:
        """ì—°êµ¬ íƒ€ì„ë¼ì¸ ìƒì„±"""
        # ì—°ë„ë³„ ë…¼ë¬¸ ë¶„í¬
        papers = results.get('papers', [])
        
        if not papers:
            return go.Figure()
        
        # ì—°ë„ ì¶”ì¶œ
        years = []
        for paper in papers:
            year = paper.get('year')
            if year:
                try:
                    years.append(int(year))
                except:
                    pass
        
        if not years:
            return go.Figure()
        
        # íˆìŠ¤í† ê·¸ë¨ ìƒì„±
        fig = go.Figure()
        fig.add_trace(go.Histogram(
            x=years,
            nbinsx=20,
            name='ë…¼ë¬¸ ìˆ˜'
        ))
        
        fig.update_layout(
            title="ì—°ë„ë³„ ì—°êµ¬ ë™í–¥",
            xaxis_title="ì—°ë„",
            yaxis_title="ë…¼ë¬¸ ìˆ˜",
            height=300
        )
        
        return fig
    
    def _analyze_research_gaps(self, results: Dict) -> List[Dict]:
        """ì—°êµ¬ ê°­ ë¶„ì„"""
        # AI ê¸°ë°˜ ì—°êµ¬ ê°­ ë¶„ì„
        prompt = f"""
        ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½:
        - ë…¼ë¬¸: {len(results.get('papers', []))}ê°œ
        - íŠ¹í—ˆ: {len(results.get('patents', []))}ê°œ
        - í”„ë¡œí† ì½œ: {len(results.get('protocols', []))}ê°œ
        - ë°ì´í„°ì…‹: {len(results.get('datasets', []))}ê°œ
        
        ì´ ë¶„ì•¼ì˜ ì—°êµ¬ ê°­ 3ê°œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
        ê° ê°­ì— ëŒ€í•´:
        1. ì œëª©
        2. ì„¤ëª…
        3. ì¶”ì²œ ì ‘ê·¼ë²•
        
        JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
        """
        
        try:
            response = self.api.get_ai_response(prompt, response_format="json")
            if response and 'gaps' in response:
                return response['gaps']
        except:
            pass
        
        # í´ë°±: ê¸°ë³¸ ê°­ ë¶„ì„
        return [
            {
                "title": "ì‹¤í—˜ ì¬í˜„ì„± ë°ì´í„° ë¶€ì¡±",
                "description": "ëŒ€ë¶€ë¶„ì˜ ë…¼ë¬¸ì´ ìƒì„¸í•œ ì‹¤í—˜ ì¡°ê±´ì„ ê³µê°œí•˜ì§€ ì•ŠìŒ",
                "recommendation": "ì˜¤í”ˆ ì‚¬ì´ì–¸ìŠ¤ í”Œë«í¼ í™œìš© ë° ìƒì„¸ í”„ë¡œí† ì½œ ê³µìœ "
            }
        ]
    
    def _download_pdf(self, pdf_url: str):
        """PDF ë‹¤ìš´ë¡œë“œ"""
        try:
            response = requests.get(pdf_url, timeout=30)
            if response.status_code == 200:
                st.download_button(
                    label="PDF ë‹¤ìš´ë¡œë“œ",
                    data=response.content,
                    file_name="paper.pdf",
                    mime="application/pdf"
                )
            else:
                st.error(f"PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ìƒíƒœ ì½”ë“œ {response.status_code}")
        except Exception as e:
            st.error(f"PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
    
    def _copy_protocol(self, protocol: Dict):
        """í”„ë¡œí† ì½œ ë³µì‚¬"""
        protocol_text = f"""
ì œëª©: {protocol['title']}
ì„¤ëª…: {protocol.get('description', '')}

ì‹¤í—˜ ë‹¨ê³„:
"""
        
        for i, step in enumerate(protocol.get('steps', [])):
            protocol_text += f"{i+1}. {step}\n"
        
        if protocol.get('materials'):
            protocol_text += "\ní•„ìš”í•œ ì¬ë£Œ:\n"
            for material in protocol['materials']:
                protocol_text += f"â€¢ {material}\n"
        
        protocol_text += f"\në‚œì´ë„: {protocol.get('difficulty', 'N/A')}"
        protocol_text += f"\nì†Œìš”ì‹œê°„: {protocol.get('duration', 'N/A')}"
        
        st.code(protocol_text)
        st.info("í”„ë¡œí† ì½œì´ í‘œì‹œë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ ë‚´ìš©ì„ ë³µì‚¬í•˜ì„¸ìš”.")
    
    def _download_dataset(self, dataset: Dict):
        """ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"""
        st.info(f"ë°ì´í„°ì…‹: {dataset['title']}")
        
        if dataset.get('files'):
            st.write("ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼:")
            for file in dataset['files']:
                if file.get('url'):
                    st.markdown(f"- [{file['name']}]({file['url']}) ({file.get('size', 0):,} bytes)")
        
        if dataset.get('doi'):
            st.write(f"DOI: {dataset['doi']}")
        
        if dataset.get('url'):
            st.write(f"ì›ë³¸ ë§í¬: {dataset['url']}")
    
    def _view_code(self, code: Dict):
        """ì½”ë“œ ë³´ê¸°"""
        with st.expander(f"ì½”ë“œ ë³´ê¸°: {code['title']}", expanded=True):
            st.write(f"**ì„¤ëª…:** {code.get('description', '')}")
            st.write(f"**ì–¸ì–´:** {code.get('language', 'Unknown')}")
            
            if code.get('repository'):
                st.write(f"**ì €ì¥ì†Œ:** {code['repository']}")
            
            if code.get('path'):
                st.write(f"**íŒŒì¼ ê²½ë¡œ:** {code['path']}")
            
            if code.get('files'):
                st.write("**íŒŒì¼ ëª©ë¡:**")
                for file in code['files']:
                    if file.get('url'):
                        st.write(f"- [{file['name']}]({file['url']})")
                    else:
                        st.write(f"- {file['name']}")
            
            st.write(f"**ì†ŒìŠ¤:** {code.get('source', '')}")
            
            if code.get('url'):
                st.write(f"**ë§í¬:** {code['url']}")
    
    def _compare_materials(self, material: Dict):
        """ì¬ë£Œ ë¹„êµ"""
        st.info("ì¬ë£Œ ë¹„êµ ê¸°ëŠ¥ì´ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.")
        
        # ì„ íƒëœ ì¬ë£Œ í‘œì‹œ
        st.write(f"ì„ íƒëœ ì¬ë£Œ: **{material['title']}**")
        
        if material.get('properties'):
            st.write("ë¬¼ì„±:")
            for prop, value in material['properties'].items():
                st.write(f"- {prop}: {value}")

# ë©”ì¸ ì‹¤í–‰
def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    manager = IntegratedResearchManager()
    manager.render_page()

if __name__ == "__main__":
    main()
